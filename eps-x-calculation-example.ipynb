{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae74719-8efc-4a21-b4e3-109bacc16b7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Below the steps to identify the most promising stocks using the EPS X appraoch\n",
    "\n",
    "1. have an excel file with all the tickers extracted from a filter on tradingview\n",
    "2. Compute the FP (see below) for all the companies\n",
    "3. Compute PFV (see below) for the all the companies\n",
    "4. Create a flag column \"below eps_pfv\" indicating whether the price is below pfv\n",
    "5. take the tickers respecting the condition 4 and create history plots\n",
    "6. select by hand the most promising stocks\n",
    "7. for the selected ones get the price to pfv ratio\n",
    "8. do an ascending sort of the stocks with the values computed in 7 and see the most promising tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ac477-e24d-4929-b554-911a0bfc0368",
   "metadata": {},
   "source": [
    "### Formula\n",
    "\n",
    "* $FP = EPS \\cdot (1 + Growth)^{Years} \\cdot PE$\n",
    "\n",
    "* $PFV = \\frac{FP}{(1 + Return)^{Years}}$\n",
    "\n",
    "In the equations : \n",
    "\n",
    "* `FP` means *Future Price* and refers to the price that the stock should have in the future\n",
    "* `PFV` mean *Present Fair Value* and refers to the price that the company should be trading today in the market\n",
    "* `EPS` refers to the EPS that we see of the company today (now, avg TTM, MRQ, etc)\n",
    "* `Growth` refers to what I think the company is going to grow in the following years\n",
    "* `Years` are the number of years to take into consideration when doing the calculation\n",
    "* `PE` refers to what I think is going to be the PE ratio after all the years considered. Thus, this is an estimated future PE ratio\n",
    "* `Return` refers to what I think is going to be the avg yearly return of the investment during all the years considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e58f7-27b9-4a7e-992a-fc0b59a19c2c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b0391-c51a-4241-9353-f6ef45af6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "import ssl\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen, Request\n",
    "from datetime import timedelta\n",
    "from typing import List, Any, Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbb621-8447-45a6-863c-8bfd5207bde2",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fd034-e5c6-4ea3-b81d-bffbf920a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_assets_factors = {\n",
    "    \"receivables_factor\": 0.8,\n",
    "    \"inventory_factor\": 0.6,\n",
    "    \"ppe_factor\": 0.67,\n",
    "}\n",
    "\n",
    "bs_cols = [\n",
    "    \"fillingDate\",\n",
    "    \"symbol\",\n",
    "    \"totalEquity\",\n",
    "    \"totalCurrentAssets\",\n",
    "    \"totalAssets\",\n",
    "    \"totalCurrentLiabilities\", \n",
    "    \"totalLiabilities\",\n",
    "    \"totalStockholdersEquity\",\n",
    "    \"totalDebt\",\n",
    "    \"goodwillAndIntangibleAssets\",\n",
    "    \"goodwill\",\n",
    "    \"intangibleAssets\",\n",
    "]\n",
    "is_cols = [\n",
    "    \"fillingDate\",\n",
    "    \"eps\",\n",
    "    \"weightedAverageShsOutDil\",\n",
    "    \"revenue\",\n",
    "    \"netIncome\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe209a-316a-451c-9b6e-a68c82858997",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9d995-de23-46dc-9443-f00762b6a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fp(\n",
    "    eps:float,\n",
    "    growth_value: float,\n",
    "    years: int,\n",
    "    future_pe: float,\n",
    ") -> float:\n",
    "    capped_growth_value = min(0.40, growth_value)\n",
    "    capped_future_pe = min(20, future_pe)\n",
    "    return eps * ((1 + capped_growth_value) ** years) * capped_future_pe\n",
    "\n",
    "def compute_pfv(fp: float, return_value: float, years: int) -> float:\n",
    "    capped_return_value = min(0.20, return_value)\n",
    "    return fp / ((1 + capped_return_value) ** years)\n",
    "\n",
    "def compute_pex_value_handler(\n",
    "    eps: float,\n",
    "    growth_value: float,\n",
    "    return_value: float,\n",
    "    future_pe: float,\n",
    "    years: int,\n",
    ") -> float:\n",
    "    fp = compute_fp(eps, growth_value, years, future_pe)\n",
    "    pfv = compute_pfv(fp, return_value, years)\n",
    "    return pfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1874a-2537-42aa-bd57-b3acb09d6705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_income_stmt_info(ticker: str, nb_years: int = 10) -> List[Dict[str, Any]]:\n",
    "    url_income_stmt = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit={nb_years}&apikey={KEY}\"\n",
    "    #response_income_stmt = urlopen(url_income_stmt, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_income_stmt = urlopen(Request(url_income_stmt), context=context)\n",
    "    data_income_stmt = response_income_stmt.read().decode(\"utf-8\")\n",
    "    data_income_stmt = json.loads(data_income_stmt)\n",
    "    return data_income_stmt\n",
    "\n",
    "def get_balance_sheet_info(ticker: str, nb_years: int = 10) -> List[Dict[str, Any]]:\n",
    "    url_balance_sheet = f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}?limit={nb_years}&apikey={KEY}\"\n",
    "    #response_balance_sheet = urlopen(url_balance_sheet, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_balance_sheet = urlopen(Request(url_balance_sheet), context=context)\n",
    "    data_balance_sheet = response_balance_sheet.read().decode(\"utf-8\")\n",
    "    data_balance_sheet = json.loads(data_balance_sheet)\n",
    "    return data_balance_sheet\n",
    "\n",
    "def get_key_from_iterator(iterator: List[Dict[str, Any]], key: str) -> List[float]:\n",
    "    all_eps = [element[key] for element in iterator]\n",
    "    return all_eps\n",
    "\n",
    "\n",
    "def compute_historical_growth(iterator: List[float]) -> List[float]:\n",
    "    all_growth = [np.nan]\n",
    "    for idx in range(1, len(iterator)):\n",
    "        all_growth.append((iterator[idx] - iterator[idx-1]) / (iterator[idx-1] + 1e-6))\n",
    "    return all_growth\n",
    "\n",
    "def drop_nans(iterator: List[float]) -> List[float]:\n",
    "    iterator_wo_nans = [element for element in iterator if not np.isnan(element)]\n",
    "    return iterator_wo_nans\n",
    "\n",
    "def compute_stat_bound(\n",
    "    iterator: List[float], q_inf: float = 0.25, q_sup: float = 0.75, distance: int = 3\n",
    ") -> Tuple[float, float]:\n",
    "    q1 = np.quantile(iterator, q_inf)\n",
    "    q3 = np.quantile(iterator, q_sup)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - distance*iqr\n",
    "    upper_bound = q3 + distance*iqr\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def compute_avg_value(iterator: List[float]) -> float:\n",
    "    avg = np.mean(iterator)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377c491-8312-4d23-ba8c-f4afc5677fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reporting_window(financial_info: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    last_report_date = financial_info[\"date\"]\n",
    "    window_start = pd.to_datetime(last_report_date) + pd.DateOffset(days=30)\n",
    "    window_start = str(window_start.date())\n",
    "    window_end = pd.to_datetime(last_report_date) + pd.DateOffset(days=46)\n",
    "    window_end = str(window_end.date())\n",
    "    return window_start, window_end\n",
    "\n",
    "# this is the new get_prices_in_range function\n",
    "def get_prices_in_range(ticker: str, window_start: str, window_end: str) -> List[Dict[str, Any]]:\n",
    "    url_prices =  f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={window_start}&to={window_end}&apikey={KEY}\"\n",
    "    #response_prices = urlopen(url_prices, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_prices = urlopen(Request(url_prices), context=context)\n",
    "    data_prices = response_prices.read().decode(\"utf-8\")\n",
    "    data_prices = json.loads(data_prices)\n",
    "    return data_prices\n",
    "\n",
    "def handling_negative_pe(iterator: List[float]) -> List[float]:\n",
    "    positive_historical_pe = [val if val > 0 else 0 for val in iterator]\n",
    "    return positive_historical_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90bc6c-9f69-438c-9631-4d96a9d17f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_price(ticker):\n",
    "    url_price = f\"https://financialmodelingprep.com/api/v3/quote/{ticker}?limit=1&apikey={KEY}\"\n",
    "    #response_price = urlopen(url_price, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_price = urlopen(Request(url_price), context=context)\n",
    "    data_price = response_price.read().decode(\"utf-8\")\n",
    "    data_price = json.loads(data_price)\n",
    "    if len(data_price) > 0:\n",
    "        data_price = data_price[0]\n",
    "        return data_price[\"price\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988989bc-fd5c-4e1a-a330-49f42982c8f8",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8e481-fafa-4931-a1c4-b3fa3363ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_PATH = \"fmi-personal-key.txt\"\n",
    "with open(KEY_PATH, \"r\") as f:\n",
    "    KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7e0f1-872e-4c07-8a38-0789f9a2e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tickers_list_03092023.txt\", \"r\") as f:\n",
    "    TICKERS = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ebc5e-9d67-4470-8397-68a84410c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = list(set(TICKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39444e50-5223-4895-a234-4c4537a7af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"CTHR\" in TICKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88db9c-2369-436d-b72d-8197f599aeb0",
   "metadata": {},
   "source": [
    "Example of EPS X calculation for CTHR\n",
    "\n",
    "There are 4 things that we need to decide to compute the value : \n",
    "\n",
    "* Return : I am going to use a standard of 20%\n",
    "* Growth : I am going to use the data of the last 10 years and the what has been the avg growth. I am going to try it with EPS and then see if it's possible to do it with equity\n",
    "* PE : The future PE ratio will be (10Y max - 10Ymin) / 2. I need to get the data from the last 10 years For the EPS it'll be straightforward, for the price I should match the eps of year X with the avg price of 3 months after the data of the report of year X\n",
    "* Years : Number of years to consider in the calculations. I will use 7 (in between 5 and 10) cuz 5 is too short and 10 is too long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84425ce5-2a21-40fd-9005-6e4b7a507da4",
   "metadata": {},
   "source": [
    "#### Return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73dbdb6-34d8-4851-a4f9-2e62c841c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_value = 0.2\n",
    "return_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67586a4-5b39-4710-a98c-3243c83664b4",
   "metadata": {},
   "source": [
    "#### Growth value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c2cb8-6cd0-4d19-98c4-ab1659b813a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4ea60-5f8b-448d-bbd0-f143f47eff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"CTHR\"\n",
    "url_income_stmt = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "response_income_stmt = urlopen(url_income_stmt, cafile=certifi.where())\n",
    "data_income_stmt = response_income_stmt.read().decode(\"utf-8\")\n",
    "data_income_stmt = json.loads(data_income_stmt)\n",
    "\n",
    "url_balance_sheet = f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "response_balance_sheet = urlopen(url_balance_sheet, cafile=certifi.where())\n",
    "data_balance_sheet = response_balance_sheet.read().decode(\"utf-8\")\n",
    "data_balance_sheet = json.loads(data_balance_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046c16e-b8d0-4e72-94c7-277c5a8d20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eps = [element[\"eps\"] for element in data_income_stmt]\n",
    "all_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20c3d8-fb35-45d8-8f41-ab3ec590c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_equity = [element[\"totalStockholdersEquity\"] for element in data_balance_sheet]\n",
    "all_equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe320c4c-8b7b-4d03-a70a-338b40003dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_growth = []\n",
    "for idx in range(1, len(all_equity)):\n",
    "    all_growth.append((all_equity[idx-1] - all_equity[idx]) / all_equity[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2db0de-926e-4c22-b5c2-cec1b90db2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20d11e-a325-43e9-a6db-806d0b02482b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cap the extreme growth rates for a more conservative approach\n",
    "# Not the extrem drops since it'll help put numbers down\n",
    "q1 = np.quantile(all_growth, 0.25)\n",
    "q3 = np.quantile(all_growth, 0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 3*iqr\n",
    "upper_bound = q3 + 3*iqr\n",
    "\n",
    "all_growth_wo_extremes = [min(element, upper_bound) for element in all_growth]# if lower_bound < element < upper_bound]\n",
    "all_growth_wo_extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb1dd9-f0e6-488e-8ed9-59916434b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ceba6-36cd-4181-821f-2fe9e3cae1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_value = np.mean(all_growth_wo_extremes)#np.mean(all_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34c220-e578-4c31-ba6f-2191a88b9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42253386-fab4-4cb9-81a4-f5efff670c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "growths = []\n",
    "for nb_years in [5, 6, 7, 8, 9]:\n",
    "    single_growth = (all_equity[0] / all_equity[nb_years-1]) ** (1/(nb_years-1)) - 1\n",
    "    print(f\"CAGR in {nb_years} years: {single_growth}\")\n",
    "    growths.append(single_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1113f-a741-46f7-bdbd-cf7e930c4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_5y = (all_equity[0] / all_equity[4]) ** (1/4) - 1\n",
    "growth_10y = (all_equity[0] / all_equity[-1]) ** (1/9) - 1\n",
    "\n",
    "(growth_5y + growth_10y) / 2, growth_5y, growth_10y, (all_equity[0] / all_equity[-4]) ** (1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565c216-4898-48d6-8edd-02c2ecb167f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ec367-b272-41e0-a977-3e7cba817851",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"CTHR\"\n",
    "data_income_stmt = get_income_stmt_info(ticker=ticker, nb_years=10)\n",
    "#all_eps = get_key_from_iterator(iterator=data_income_stmt, key=\"eps\")\n",
    "all_equity = get_key_from_iterator(iterator=data_balance_sheet, key=\"totalStockholdersEquity\")\n",
    "#all_growth = compute_historical_growth(all_eps)\n",
    "all_growth = compute_historical_growth(all_equity)\n",
    "growth_5y = (all_equity[0] / all_equity[4]) ** (1/4) - 1\n",
    "growth_10y = (all_equity[0] / all_equity[-1]) ** (1/9) - 1\n",
    "growth_value = (growth_5y + growth_10y) / 2\n",
    "growths = []\n",
    "for nb_years in [5, 6, 7, 8, 9]:\n",
    "    single_growth = (all_equity[0] / all_equity[nb_years-1]) ** (1/(nb_years-1)) - 1\n",
    "    growths.append(single_growth)\n",
    "growth_value = np.median(growths)\n",
    "growth_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d94be-30bb-416a-bb5f-b8da2cf6733a",
   "metadata": {},
   "source": [
    "#### Future PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f884a-9c3b-4554-b0ce-41c90f3820db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reporting of a period is expected between 30 - 45 days after the ending of that period\n",
    "all_prices = []\n",
    "for single_income_stmt in data_income_stmt:\n",
    "    reporting_window_start = pd.to_datetime(single_income_stmt[\"date\"]) + pd.DateOffset(days=30)\n",
    "    reporting_window_start = str(reporting_window_start.date())\n",
    "    reporting_window_end = pd.to_datetime(single_income_stmt[\"date\"]) + pd.DateOffset(days=46)\n",
    "    reporting_window_end = str(reporting_window_end.date())\n",
    "    \n",
    "    url_prices =  f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={reporting_window_start}&to={reporting_window_end}&apikey={KEY}\"\n",
    "    response_prices = urlopen(url_prices, cafile=certifi.where())\n",
    "    data_prices = response_prices.read().decode(\"utf-8\")\n",
    "    data_prices = json.loads(data_prices)\n",
    "    \n",
    "    price_at_report = np.mean([element[\"low\"] for element in data_prices[\"historical\"]])\n",
    "    \n",
    "    all_prices.append(price_at_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebc1f2-658c-4537-8e73-0c85a29a55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb6136-04af-4641-a0f9-516ed3829c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't like a pe of zero cuz we mask very big drops that could hide info\n",
    "historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "historical_pe = [val if val > 0 else 0 for val in historical_pe]\n",
    "historical_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12825898-8791-42b5-8c46-95a99d52d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pe = np.mean(historical_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8e9d9-ab29-475a-84eb-f9d74c036590",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b6f4e-47bd-43a3-a87f-80f36f1de4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reporting_window(financial_info: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    last_report_date = financial_info[\"date\"]\n",
    "    window_start = pd.to_datetime(last_report_date) + pd.DateOffset(days=30)\n",
    "    window_start = str(window_start.date())\n",
    "    window_end = pd.to_datetime(last_report_date) + pd.DateOffset(days=46)\n",
    "    window_end = str(window_end.date())\n",
    "    return window_start, window_end\n",
    "\n",
    "# this is the old get_prices_in_range function\n",
    "\"\"\"def get_prices_in_range(ticker: str, window_start: str, window_end: str) -> List[Dict[str, Any]]:\n",
    "    url_prices =  f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={window_start}&to={window_end}&apikey={KEY}\"\n",
    "    response_prices = urlopen(url_prices, cafile=certifi.where())\n",
    "    data_prices = response_prices.read().decode(\"utf-8\")\n",
    "    data_prices = json.loads(data_prices)\n",
    "    return data_prices\"\"\"\n",
    "\n",
    "def handling_negative_pe(iterator: List[float]) -> List[float]:\n",
    "    positive_historical_pe = [val if val > 0 else 0 for val in iterator]\n",
    "    return positive_historical_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0694019-4604-40b1-bfa7-0c4a6db3fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e00de4-2b14-408e-b884-2b11fafb0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prices = []\n",
    "for single_income_stmt in data_income_stmt:#[::-1]:\n",
    "    reporting_start, reporting_end = get_reporting_window(single_income_stmt)\n",
    "    data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "    range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "    avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "    all_prices.append(avg_price_at_report)\n",
    "    \n",
    "historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "historical_pe = handling_negative_pe(historical_pe)\n",
    "future_pe = compute_avg_value(historical_pe)\n",
    "future_pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8126e2-6382-4f50-89dc-f7c134866982",
   "metadata": {},
   "source": [
    "#### Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b684a75-1b47-4da2-be01-7dfd6d895e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e127b-2514-43da-b3c3-dee7871f427b",
   "metadata": {},
   "source": [
    "#### Calculations\n",
    "\n",
    "Reminder:\n",
    "\n",
    "* $FP = EPS \\cdot (1 + Growth)^{Years} \\cdot PE$\n",
    "\n",
    "* $PFV = \\frac{FP}{(1 + Return)^{Years}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9e980-17a5-4832-8a8a-027e687f0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261f2d4-a5e2-4302-9713-be2e29ad4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = all_eps[0] # latest yearly EPS\n",
    "\n",
    "fp = eps * ((1 + growth_value) ** years) * future_pe\n",
    "pfv = fp / ((1 + return_value) ** years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe60c9-0204-4fad-979a-d73d3874cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_price = pfv * 0.5\n",
    "print(f\"Present Faire Value:   {round(pfv, 2)}\")\n",
    "print(f\"Buying Price:          {round(buy_price, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6eb720-9111-4d60-9ac8-e47accc6a51c",
   "metadata": {},
   "source": [
    "**NOTES** : \n",
    "\n",
    "* The higher the future PE ratio the higher the present faire value. -> Choose a conservative PE ratio\n",
    "* The higher the number of years the higher the present faire value (assuming the same number of years considered for both future price and present faire value). -> Choose a mid-term horizon\n",
    "* For a fixed rate of return (return_value), the greater the growth_value the greater the present faire value. -> Choose a conservative growth value\n",
    "* For a fixed growth_value, the greater the rate of return the lower the present faire value. -> Choose a slightly high rate of return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ea9bf-6efe-4455-87aa-13711c921bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfv_conservative = compute_pex_value_handler(eps, growth_value, return_value, future_pe, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5fe05-606b-4443-9762-718075a32ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_price_conservative = pfv_conservative * 0.5\n",
    "print(f\"Present Faire Value:   {round(pfv_conservative, 2)}\")\n",
    "print(f\"Buying Price:          {round(buy_price_conservative, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f5386-e668-495f-b29a-d0ffedb97b8f",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "* Compute the growth with the equity instead of the eps\n",
    "* Compute the PE with the fillinDate instead of the range of dates selected by hand\n",
    "* Information of the last 10 years to plot:\n",
    "    * pfv\n",
    "    * Equity (book value)\n",
    "    * Tangible book value\n",
    "    * Current ratio\n",
    "    * Shares outstanding\n",
    "    * PE ratio\n",
    "    * The 3 DE ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f5346-64d6-4184-9365-3300d663dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pex_value(deco, growth_value, return_value, future_pe, years) -> float:\n",
    "    eps = deco.get(\"eps\", 0)\n",
    "    pfv = compute_pex_value_handler(\n",
    "        eps, growth_value, return_value, future_pe, years\n",
    "    )\n",
    "    return pfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59c774-fcb2-4133-a53a-fd0a28bbd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tangible_book_value(deco):\n",
    "    if \"goodwillAndIntangibleAssets\" not in deco:\n",
    "        intangible_assets = deco.get(\"goodwill\", 0) + deco.get(\"intangibleAssets\", 0)\n",
    "    else:\n",
    "        intangible_assets = deco.get(\"goodwillAndIntangibleAssets\", 0)\n",
    "    tangible_assets = deco.get(\"totalAssets\") - intangible_assets\n",
    "    tangible_book_value = tangible_assets - deco.get(\"totalLiab\", 0)\n",
    "    return tangible_book_value\n",
    "\n",
    "def compute_tangible_book_value_ps(deco):\n",
    "    tangible_book_value = compute_tangible_book_value(deco)\n",
    "    nb_outs_shares = deco.get(\"weightedAverageShsOutDil\", np.Inf)\n",
    "    if nb_outs_shares == 0:\n",
    "        nb_outs_shares = np.Inf\n",
    "    return tangible_book_value / nb_outs_shares\n",
    "\n",
    "def compute_discounted_tangible_book_value(deco, factors_deco):\n",
    "    if \"goodwillAndIntangibleAssets\" not in deco:\n",
    "        intangible_assets = deco.get(\"goodwill\", 0) + deco.get(\"intangibleAssets\", 0)\n",
    "    else:\n",
    "        intangible_assets = deco.get(\"goodwillAndIntangibleAssets\", 0)\n",
    "    discounted_tangible_assets = (\n",
    "        deco.get(\"totalAssets\") - intangible_assets - (\n",
    "            (1 - factors_deco[\"receivables_factor\"]) * deco.get(\"netReceivables\", 0) +\n",
    "            (1 - factors_deco[\"inventory_factor\"]) * deco.get(\"inventory\", 0) +\n",
    "            (1 - factors_deco[\"ppe_factor\"]) * deco.get(\"propertyPlantEquipmentNet\", 0)\n",
    "        )\n",
    "    )\n",
    "    discounted_tangible_book_value = discounted_tangible_assets - deco.get(\"totalLiab\", 0)\n",
    "    return discounted_tangible_book_value\n",
    "\n",
    "def compute_discounted_tangible_book_value_ps(deco, factors_deco):\n",
    "    tangible_book_value = compute_discounted_tangible_book_value(deco, factors_deco)\n",
    "    nb_outs_shares = deco.get(\"weightedAverageShsOutDil\", np.Inf)\n",
    "    return tangible_book_value / nb_outs_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebfb3d-4dc6-4f5e-a392-6928ac8b90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_current_ratio(deco) -> float:\n",
    "    return deco.get(\"totalCurrentAssets\", 0) / (deco.get(\"totalCurrentLiabilities\", 0) + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aced026-3063-44c9-8802-06148659779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the old compute_price_at_reporting_date function\n",
    "\"\"\"def compute_price_at_reporting_date(deco):\n",
    "    filling_date = deco.get(\"filling_date\", None)\n",
    "    if filling_date is None:\n",
    "        # if we don't have a filling date we will take a window of 30 - 45 days for the price\n",
    "        reporting_start, reporting_end = get_reporting_window(single_income_stmt)\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "        avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "    else:\n",
    "        # if we have a filling date we will take the price from that day and the following trading day\n",
    "        reporting_start = filling_date\n",
    "        reporting_datetime = pd.to_datetime(filling_date) + pd.DateOffset(days=3)\n",
    "        reporting_end = str(reporting_datetime.date())\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        data_prices = data_prices[:2]\n",
    "        range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "        avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "    return avg_price_at_report\"\"\"\n",
    "\n",
    "def compute_pe_ratio(deco):\n",
    "    eps = deco.get(\"eps\", 0)\n",
    "    pps = deco.get(\"reporting_date_price\", 1e-5)\n",
    "    return eps/pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2da03d-eaea-484a-b13e-56c2bf72cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_de_ratio1(deco) -> float:\n",
    "    return deco[\"totalLiabilities\"] / (deco[\"totalStockholdersEquity\"] + 0.1)\n",
    "\n",
    "def compute_de_ratio2(deco) -> float:\n",
    "    return deco[\"totalCurrentLiabilities\"] / (deco[\"totalStockholdersEquity\"] + 0.1)\n",
    "\n",
    "def compute_de_ratio3(deco) -> float:\n",
    "    return deco[\"totalDebt\"] / (deco[\"totalStockholdersEquity\"] + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2ba5e-f371-4552-a215-7d741679a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indicators(df: pd.DataFrame) -> None:\n",
    "    fig, ax = plt.subplots(1, 13, figsize=(26, 3))\n",
    "    df[\"pfvps\"].plot.bar(ax=ax[0], title = \"pfvps\")\n",
    "    df[\"pe_ratio\"].plot.bar(ax=ax[1], title = \"pe ratio\")\n",
    "    df[\"revenue\"].plot.bar(ax=ax[2], title = \"revenues\")\n",
    "    df[\"netIncome\"].plot.bar(ax=ax[3], title = \"net income\")\n",
    "    df[\"eps\"].plot.bar(ax=ax[4], title = \"eps\")\n",
    "    df[\"totalAssets\"].plot.bar(ax=ax[5], title = \"total assets\")\n",
    "    df[\"totalLiabilities\"].plot.bar(ax=ax[6], title = \"total liab\")\n",
    "    min_ylim, max_ylim = (\n",
    "        min(df[\"totalAssets\"].min(), df[\"totalLiabilities\"].min()),\n",
    "        max(df[\"totalAssets\"].max(), df[\"totalLiabilities\"].max()),\n",
    "    )\n",
    "    ax[5].set_ylim([min_ylim, max_ylim])\n",
    "    ax[6].set_ylim([min_ylim, max_ylim])\n",
    "    del min_ylim\n",
    "    del max_ylim\n",
    "    df[\"totalEquity\"].plot.bar(ax=ax[7], title = \"total equity\")\n",
    "    df[\"tangible_book_value_ps\"].plot.bar(ax=ax[8], title = \"tangible book value\")\n",
    "    #df[\"dct_tangible_book_value_ps\"].plot.bar(ax=ax[3], title = \"dct tangible book value\")\n",
    "    #df[\"current_ratio\"].plot.bar(ax=ax[4], title = \"current ratio\")\n",
    "    df[\"weightedAverageShsOutDil\"].plot.bar(ax=ax[9], title = \"shares outs\")\n",
    "    df[\"de_ratio1\"].plot.bar(ax=ax[10], title = \"total liab / shares outs\")\n",
    "    df[\"de_ratio2\"].plot.bar(ax=ax[11], title = \"current liab / shares outs\")\n",
    "    df[\"de_ratio3\"].plot.bar(ax=ax[12], title = \"total debt / shares outs\")\n",
    "    min_ylim, max_ylim = (\n",
    "        min(df[\"de_ratio1\"].min(), df[\"de_ratio2\"].min(), df[\"de_ratio3\"].min()),\n",
    "        max(df[\"de_ratio1\"].max(), df[\"de_ratio2\"].max(), df[\"de_ratio3\"].max())\n",
    "    )\n",
    "    ax[10].set_ylim([min_ylim, max_ylim])\n",
    "    ax[11].set_ylim([min_ylim, max_ylim])\n",
    "    ax[12].set_ylim([min_ylim, max_ylim])\n",
    "    del min_ylim\n",
    "    del max_ylim\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26063f9-e1fe-4dae-829d-3075665e2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in [\"CTHR\"]:\n",
    "    # define urls\n",
    "    url_balance_sheet = f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "    url_income_stmt = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "    try:\n",
    "        # load data\n",
    "        response_balance_sheet = urlopen(url_balance_sheet, cafile=certifi.where())\n",
    "        response_income_stmt = urlopen(url_income_stmt, cafile=certifi.where())\n",
    "    except:\n",
    "        missed_tickers.append(ticker)\n",
    "    data_balance_sheet = response_balance_sheet.read().decode(\"utf-8\")\n",
    "    data_balance_sheet = json.loads(data_balance_sheet)\n",
    "    if len(data_balance_sheet) < 5:\n",
    "        continue\n",
    "\n",
    "    data_income_stmt = response_income_stmt.read().decode(\"utf-8\")\n",
    "    data_income_stmt = json.loads(data_income_stmt)\n",
    "    if len(data_income_stmt) < 5:\n",
    "        continue\n",
    "        \n",
    "    balance_sheet_df = pd.DataFrame(data_balance_sheet)\n",
    "    income_stmt_df = pd.DataFrame(data_income_stmt)\n",
    "    balance_sheet_df = balance_sheet_df.set_index(\"date\")\n",
    "    income_stmt_df = income_stmt_df.set_index(\"date\")\n",
    "    balance_sheet_df = balance_sheet_df[bs_cols]\n",
    "    income_stmt_df = income_stmt_df[is_cols]\n",
    "    balance_sheet_df = balance_sheet_df.rename(columns={\"fillingDate\":\"fillingDateBalanceSheet\"})\n",
    "\n",
    "    fs_df = pd.concat([balance_sheet_df, income_stmt_df], axis=1, join=\"inner\")\n",
    "    fs_df = fs_df.iloc[::-1] # from oldest to newest\n",
    "    \n",
    "    # compute PFV\n",
    "    fs_df[\"pfvps\"] = fs_df.apply(compute_pex_value, args=(growth_value, return_value, future_pe, years,), axis=1)\n",
    "    # compute tangible book value per share\n",
    "    fs_df[\"tangible_book_value_ps\"] = fs_df.apply(compute_tangible_book_value_ps, axis=1)\n",
    "    # compute discounted tangible book value per share\n",
    "    #fs_df[\"dct_tangible_book_value_ps\"] = fs_df.apply(compute_discounted_tangible_book_value_ps, args=(current_assets_factors, ), axis=1)\n",
    "    # compute current ratio\n",
    "    #fs_df[\"current_ratio\"] = fs_df.apply(compute_current_ratio, axis=1)\n",
    "    # get price at report date\n",
    "    fs_df[\"reporting_date_price\"] = fs_df.apply(compute_price_at_reporting_date, axis=1)\n",
    "    # compute pe ratio\n",
    "    fs_df[\"pe_ratio\"] = fs_df.apply(compute_pe_ratio, axis=1)\n",
    "    # compute de ratio 1\n",
    "    fs_df[\"de_ratio1\"] = fs_df.apply(compute_de_ratio1, axis=1)\n",
    "    # compute de ratio 2\n",
    "    fs_df[\"de_ratio2\"] = fs_df.apply(compute_de_ratio2, axis=1)\n",
    "    # compute de ratio 3\n",
    "    fs_df[\"de_ratio3\"] = fs_df.apply(compute_de_ratio3, axis=1)\n",
    "\n",
    "    # plot indicators\n",
    "    print(ticker)\n",
    "    plot_indicators(fs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20964e-1754-4fc6-88be-d44b053a1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "growths = []\n",
    "for nb_years in [5, 6, 7, 8, 9]:\n",
    "    single_growth = (all_equity[0] / all_equity[nb_years-1]) ** (1/(nb_years-1)) - 1\n",
    "    print(f\"CAGR in {nb_years} years: {single_growth}\")\n",
    "    growths.append(single_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4b59c-08e0-438f-912c-e2b8da9b5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(growths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797ba95-9122-49f5-865e-71ac9c5e269a",
   "metadata": {},
   "source": [
    "TODO :\n",
    "\n",
    "* The growth in equity is computed with growth and not with equity_growth (though it sounds stupid I just did that)\n",
    "* To filter out companies from the first list I can use negative equity and price > pfv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d036425f-3234-4452-b06e-2904632ce703",
   "metadata": {},
   "source": [
    "## For all the companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc29498-d49e-4c0a-813f-7fdfa9f9a426",
   "metadata": {},
   "source": [
    "**NOTE:** The years and the return value will not change. The values that will depend on the ticker are the growth value and the future pe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164085e5-5035-4f29-9ec7-3705ae40793e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_tickers = []\n",
    "overvalued_tickers = []\n",
    "for ticker in tqdm(TICKERS):\n",
    "    #if ticker != \"CMC\":\n",
    "    #    continue\n",
    "    # Get income stmt and balance sheet information\n",
    "    try:\n",
    "        data_income_stmt = get_income_stmt_info(ticker=ticker, nb_years=10)\n",
    "        data_balance_sheet = get_balance_sheet_info(ticker=ticker, nb_years=10)\n",
    "    except:\n",
    "        missing_tickers.append(ticker)\n",
    "        \n",
    "    # Do data manipulations\n",
    "    if len(data_balance_sheet) < 5 or len(data_income_stmt) < 5:\n",
    "        continue\n",
    "    balance_sheet_df = pd.DataFrame(data_balance_sheet)\n",
    "    income_stmt_df = pd.DataFrame(data_income_stmt)\n",
    "    balance_sheet_df = balance_sheet_df.set_index(\"date\")\n",
    "    income_stmt_df = income_stmt_df.set_index(\"date\")\n",
    "    balance_sheet_df = balance_sheet_df[bs_cols]\n",
    "    income_stmt_df = income_stmt_df[is_cols]\n",
    "    balance_sheet_df = balance_sheet_df.rename(columns={\"fillingDate\":\"fillingDateBalanceSheet\"})\n",
    "    \n",
    "    \n",
    "    # compute growth value\n",
    "    all_equity = get_key_from_iterator(iterator=data_balance_sheet, key=\"totalStockholdersEquity\")\n",
    "    all_growth = compute_historical_growth(all_equity)\n",
    "    #growth_5y = (all_equity[0] / (all_equity[4] + 0.001)) ** (1/4) - 1\n",
    "    #growth_10y = (all_equity[0] / (all_equity[-1] + 0.001)) ** (1/9) - 1\n",
    "    #growth_value = (growth_5y + growth_10y) / 2\n",
    "    growths = []\n",
    "    for nb_years in range(5, len(all_equity)+1):#6, 7, 8, 9]:\n",
    "        single_growth = (all_equity[0] / (all_equity[nb_years-1] + 0.001)) ** (1/(nb_years-1)) - 1\n",
    "        growths.append(single_growth)\n",
    "    growth_value = np.median(growths)\n",
    "    # compute future pe ratio\n",
    "    all_prices = []\n",
    "    for single_income_stmt in data_income_stmt:\n",
    "        reporting_start, reporting_end = get_reporting_window(single_income_stmt)\n",
    "        data_prices = get_prices_in_range(ticker, reporting_start, reporting_end)\n",
    "        #print(data_prices)\n",
    "        #print()\n",
    "        try: # if we cannot get the value of the price cuz empty dict, for now we set it to zero\n",
    "            range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        except:\n",
    "            avg_price_at_report = 0\n",
    "        all_prices.append(avg_price_at_report)\n",
    "    all_eps = get_key_from_iterator(iterator=data_income_stmt, key=\"eps\")\n",
    "    all_eps = [val if val != 0 else 1e-6 for val in all_eps]\n",
    "    historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "    historical_pe = handling_negative_pe(historical_pe)\n",
    "    future_pe = compute_avg_value(historical_pe)\n",
    "    \n",
    "    # compute present faire value\n",
    "    pfvps = compute_pex_value(data_income_stmt[0], growth_value, return_value, future_pe, years)\n",
    "    \n",
    "    # get current price\n",
    "    current_price = get_current_price(ticker)\n",
    "    \n",
    "    # filter out companies with price > fpv\n",
    "    if current_price is None or current_price > pfvps:\n",
    "        overvalued_tickers.append(ticker)\n",
    "        continue\n",
    "    # compute stuff to plot\n",
    "    fs_df = pd.concat([balance_sheet_df, income_stmt_df], axis=1, join=\"inner\")\n",
    "    fs_df = fs_df.iloc[::-1] # from oldest to newest\n",
    "    \n",
    "    # compute PFV\n",
    "    fs_df[\"pfvps\"] = fs_df.apply(compute_pex_value, args=(growth_value, return_value, future_pe, years,), axis=1)\n",
    "    # compute tangible book value per share\n",
    "    fs_df[\"tangible_book_value_ps\"] = fs_df.apply(compute_tangible_book_value_ps, axis=1)\n",
    "    # compute discounted tangible book value per share\n",
    "    #fs_df[\"dct_tangible_book_value_ps\"] = fs_df.apply(compute_discounted_tangible_book_value_ps, args=(current_assets_factors, ), axis=1)\n",
    "    # compute current ratio\n",
    "    #fs_df[\"current_ratio\"] = fs_df.apply(compute_current_ratio, axis=1)\n",
    "    # get price at report date\n",
    "    fs_df[\"reporting_date_price\"] = pd.Series(fs_df.reset_index().apply(compute_price_at_reporting_date, axis=1), index=fs_df.index)\n",
    "    # compute pe ratio\n",
    "    fs_df[\"pe_ratio\"] = fs_df.apply(compute_pe_ratio, axis=1)\n",
    "    # compute de ratio 1\n",
    "    fs_df[\"de_ratio1\"] = fs_df.apply(compute_de_ratio1, axis=1)\n",
    "    # compute de ratio 2\n",
    "    fs_df[\"de_ratio2\"] = fs_df.apply(compute_de_ratio2, axis=1)\n",
    "    # compute de ratio 3\n",
    "    fs_df[\"de_ratio3\"] = fs_df.apply(compute_de_ratio3, axis=1)\n",
    "    \n",
    "    # plot indicators\n",
    "    print(f\"{ticker}.\\t Current price: {current_price}.\\t Faire price: {pfvps}\")\n",
    "    plot_indicators(fs_df)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899f222-a268-4869-b319-1d59658210ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reporting_window(financial_info: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    last_report_date = financial_info[\"date\"]\n",
    "    window_start = pd.to_datetime(last_report_date) + pd.DateOffset(days=30)\n",
    "    window_start = str(window_start.date())\n",
    "    window_end = pd.to_datetime(last_report_date) + pd.DateOffset(days=46)\n",
    "    window_end = str(window_end.date())\n",
    "    return window_start, window_end\n",
    "\n",
    "# this is the right compute_price_at_reporting_date function\n",
    "def compute_price_at_reporting_date(deco):\n",
    "    filling_date = deco.get(\"fillingDate\", None)\n",
    "    if filling_date is None:\n",
    "        # if we don't have a filling date we will take a window of 30 - 45 days for the price\n",
    "        reporting_start, reporting_end = get_reporting_window(deco)\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        if len(data_prices):\n",
    "            range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        else:\n",
    "            avg_price_at_report = 5000\n",
    "    else:\n",
    "        # if we have a filling date we will take the price from that day and the following trading day\n",
    "        reporting_start = filling_date\n",
    "        reporting_datetime = pd.to_datetime(filling_date) + pd.DateOffset(days=3)\n",
    "        reporting_end = str(reporting_datetime.date())\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        if len(data_prices):\n",
    "            data_prices_historical = data_prices[\"historical\"][:2]\n",
    "            range_price_lows = get_key_from_iterator(data_prices_historical, \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        else:\n",
    "            avg_price_at_report = 1000\n",
    "    return avg_price_at_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c91ffc-7489-424d-b309-a56c8ecce94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "value_investment",
   "language": "python",
   "name": "value_investment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
