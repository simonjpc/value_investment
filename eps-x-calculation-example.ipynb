{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae74719-8efc-4a21-b4e3-109bacc16b7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Below the steps to identify the most promising stocks using the EPS X appraoch\n",
    "\n",
    "1. have an excel file with all the tickers extracted from a filter on tradingview\n",
    "2. Compute the FP (see below) for all the companies\n",
    "3. Compute PFV (see below) for the all the companies\n",
    "4. Create a flag column \"below eps_pfv\" indicating whether the price is below pfv\n",
    "5. take the tickers respecting the condition 4 and create history plots\n",
    "6. select by hand the most promising stocks\n",
    "7. for the selected ones get the price to pfv ratio\n",
    "8. do an ascending sort of the stocks with the values computed in 7 and see the most promising tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ac477-e24d-4929-b554-911a0bfc0368",
   "metadata": {},
   "source": [
    "### Formula\n",
    "\n",
    "* $FP = EPS \\cdot (1 + Growth)^{Years} \\cdot PE$\n",
    "\n",
    "* $PFV = \\frac{FP}{(1 + Return)^{Years}}$\n",
    "\n",
    "In the equations : \n",
    "\n",
    "* `FP` means *Future Price* and refers to the price that the stock should have in the future\n",
    "* `PFV` mean *Present Fair Value* and refers to the price that the company should be trading today in the market\n",
    "* `EPS` refers to the EPS that we see of the company today (now, avg TTM, MRQ, etc)\n",
    "* `Growth` refers to what I think the company is going to grow in the following years\n",
    "* `Years` are the number of years to take into consideration when doing the calculation\n",
    "* `PE` refers to what I think is going to be the PE ratio after all the years considered. Thus, this is an estimated future PE ratio\n",
    "* `Return` refers to what I think is going to be the avg yearly return of the investment during all the years considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e58f7-27b9-4a7e-992a-fc0b59a19c2c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8b0391-c51a-4241-9353-f6ef45af6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "import ssl\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "from datetime import timedelta\n",
    "from typing import List, Any, Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbb621-8447-45a6-863c-8bfd5207bde2",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08fd034-e5c6-4ea3-b81d-bffbf920a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_assets_factors = {\n",
    "    \"receivables_factor\": 0.8,\n",
    "    \"inventory_factor\": 0.6,\n",
    "    \"ppe_factor\": 0.67,\n",
    "}\n",
    "\n",
    "bs_cols = [\n",
    "    \"fillingDate\",\n",
    "    \"symbol\",\n",
    "    \"totalEquity\",\n",
    "    \"totalCurrentAssets\",\n",
    "    \"totalAssets\",\n",
    "    \"totalCurrentLiabilities\", \n",
    "    \"totalLiabilities\",\n",
    "    \"totalStockholdersEquity\",\n",
    "    \"totalDebt\",\n",
    "    \"goodwillAndIntangibleAssets\",\n",
    "    \"goodwill\",\n",
    "    \"intangibleAssets\",\n",
    "]\n",
    "is_cols = [\n",
    "    \"fillingDate\",\n",
    "    \"eps\",\n",
    "    \"weightedAverageShsOutDil\",\n",
    "    \"revenue\",\n",
    "    \"netIncome\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe209a-316a-451c-9b6e-a68c82858997",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d9d995-de23-46dc-9443-f00762b6a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fp(\n",
    "    eps:float,\n",
    "    growth_value: float,\n",
    "    years: int,\n",
    "    future_pe: float,\n",
    ") -> float:\n",
    "    capped_growth_value = min(0.40, growth_value)\n",
    "    capped_future_pe = min(20, future_pe)\n",
    "    return eps * ((1 + capped_growth_value) ** years) * capped_future_pe\n",
    "\n",
    "def compute_pfv(fp: float, return_value: float, years: int) -> float:\n",
    "    capped_return_value = min(0.20, return_value)\n",
    "    return fp / ((1 + capped_return_value) ** years)\n",
    "\n",
    "def compute_pex_value_handler(\n",
    "    eps: float,\n",
    "    growth_value: float,\n",
    "    return_value: float,\n",
    "    future_pe: float,\n",
    "    years: int,\n",
    ") -> float:\n",
    "    fp = compute_fp(eps, growth_value, years, future_pe)\n",
    "    pfv = compute_pfv(fp, return_value, years)\n",
    "    return pfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68e1874a-2537-42aa-bd57-b3acb09d6705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_income_stmt_info(ticker: str, nb_years: int = 10) -> List[Dict[str, Any]]:\n",
    "    url_income_stmt = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit={nb_years}&apikey={KEY}\"\n",
    "    #response_income_stmt = urlopen(url_income_stmt, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_income_stmt = urlopen(Request(url_income_stmt), context=context)\n",
    "    data_income_stmt = response_income_stmt.read().decode(\"utf-8\")\n",
    "    data_income_stmt = json.loads(data_income_stmt)\n",
    "    return data_income_stmt\n",
    "\n",
    "def get_balance_sheet_info(ticker: str, nb_years: int = 10) -> List[Dict[str, Any]]:\n",
    "    url_balance_sheet = f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}?limit={nb_years}&apikey={KEY}\"\n",
    "    #response_balance_sheet = urlopen(url_balance_sheet, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_balance_sheet = urlopen(Request(url_balance_sheet), context=context)\n",
    "    data_balance_sheet = response_balance_sheet.read().decode(\"utf-8\")\n",
    "    data_balance_sheet = json.loads(data_balance_sheet)\n",
    "    return data_balance_sheet\n",
    "\n",
    "def get_key_from_iterator(iterator: List[Dict[str, Any]], key: str) -> List[float]:\n",
    "    all_eps = [element[key] for element in iterator]\n",
    "    return all_eps\n",
    "\n",
    "def compute_historical_growth(iterator: List[float]) -> List[float]:\n",
    "    all_growth = [np.nan]\n",
    "    for idx in range(1, len(iterator)):\n",
    "        all_growth.append((iterator[idx] - iterator[idx-1]) / (iterator[idx-1] + 1e-6))\n",
    "    return all_growth\n",
    "\n",
    "def drop_nans(iterator: List[float]) -> List[float]:\n",
    "    iterator_wo_nans = [element for element in iterator if not np.isnan(element)]\n",
    "    return iterator_wo_nans\n",
    "\n",
    "def compute_stat_bound(\n",
    "    iterator: List[float], q_inf: float = 0.25, q_sup: float = 0.75, distance: int = 3\n",
    ") -> Tuple[float, float]:\n",
    "    q1 = np.quantile(iterator, q_inf)\n",
    "    q3 = np.quantile(iterator, q_sup)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - distance*iqr\n",
    "    upper_bound = q3 + distance*iqr\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def compute_avg_value(iterator: List[float]) -> float:\n",
    "    return np.mean(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7377c491-8312-4d23-ba8c-f4afc5677fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reporting_window(financial_info: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    last_report_date = financial_info[\"date\"]\n",
    "    window_start = pd.to_datetime(last_report_date) + pd.DateOffset(days=30)\n",
    "    window_start = str(window_start.date())\n",
    "    window_end = pd.to_datetime(last_report_date) + pd.DateOffset(days=46)\n",
    "    window_end = str(window_end.date())\n",
    "    return window_start, window_end\n",
    "\n",
    "# this is the new get_prices_in_range function\n",
    "def get_prices_in_range(ticker: str, window_start: str, window_end: str) -> List[Dict[str, Any]]:\n",
    "    url_prices =  f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={window_start}&to={window_end}&apikey={KEY}\"\n",
    "    #response_prices = urlopen(url_prices, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_prices = urlopen(Request(url_prices), context=context)\n",
    "    data_prices = response_prices.read().decode(\"utf-8\")\n",
    "    data_prices = json.loads(data_prices)\n",
    "    return data_prices\n",
    "\n",
    "def handling_negative_pe(iterator: List[float]) -> List[float]:\n",
    "    positive_historical_pe = [val if val > 0 else 0 for val in iterator]\n",
    "    return positive_historical_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc90bc6c-9f69-438c-9631-4d96a9d17f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_price(ticker):\n",
    "    url_price = f\"https://financialmodelingprep.com/api/v3/quote/{ticker}?limit=1&apikey={KEY}\"\n",
    "    #response_price = urlopen(url_price, cafile=certifi.where())\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    response_price = urlopen(Request(url_price), context=context)\n",
    "    data_price = response_price.read().decode(\"utf-8\")\n",
    "    data_price = json.loads(data_price)\n",
    "    print(data_price)\n",
    "    if len(data_price) > 0:\n",
    "        data_price = data_price[0]\n",
    "        return data_price[\"price\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988989bc-fd5c-4e1a-a330-49f42982c8f8",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c8e481-fafa-4931-a1c4-b3fa3363ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_PATH = \"fmi-personal-key.txt\"\n",
    "with open(KEY_PATH, \"r\") as f:\n",
    "    KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a7e0f1-872e-4c07-8a38-0789f9a2e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tickers_list_03092023.txt\", \"r\") as f:\n",
    "    TICKERS = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62ebc5e-9d67-4470-8397-68a84410c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = list(set(TICKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39444e50-5223-4895-a234-4c4537a7af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"CTHR\" in TICKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88db9c-2369-436d-b72d-8197f599aeb0",
   "metadata": {},
   "source": [
    "Example of EPS X calculation for CTHR\n",
    "\n",
    "There are 4 things that we need to decide to compute the value : \n",
    "\n",
    "* Return : I am going to use a standard of 20%\n",
    "* Growth : I am going to use the data of the last 10 years and the what has been the avg growth. I am going to try it with EPS and then see if it's possible to do it with equity\n",
    "* PE : The future PE ratio will be (10Y max - 10Ymin) / 2. I need to get the data from the last 10 years For the EPS it'll be straightforward, for the price I should match the eps of year X with the avg price of 3 months after the data of the report of year X\n",
    "* Years : Number of years to consider in the calculations. I will use 7 (in between 5 and 10) cuz 5 is too short and 10 is too long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84425ce5-2a21-40fd-9005-6e4b7a507da4",
   "metadata": {},
   "source": [
    "#### Return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c73dbdb6-34d8-4851-a4f9-2e62c841c381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_value = 0.2\n",
    "return_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67586a4-5b39-4710-a98c-3243c83664b4",
   "metadata": {},
   "source": [
    "#### Growth value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d94c2cb8-6cd0-4d19-98c4-ab1659b813a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a4ea60-5f8b-448d-bbd0-f143f47eff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/pm_1h_jn1gs2n48rx1j1ygsr0000gn/T/ipykernel_96017/1957278362.py:3: DeprecationWarning: cafile, capath and cadefault are deprecated, use a custom context instead.\n",
      "  response_income_stmt = urlopen(url_income_stmt, cafile=certifi.where())\n",
      "/var/folders/mr/pm_1h_jn1gs2n48rx1j1ygsr0000gn/T/ipykernel_96017/1957278362.py:8: DeprecationWarning: cafile, capath and cadefault are deprecated, use a custom context instead.\n",
      "  response_balance_sheet = urlopen(url_balance_sheet, cafile=certifi.where())\n"
     ]
    }
   ],
   "source": [
    "ticker = \"SSY\"\n",
    "url_income_stmt = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "response_income_stmt = urlopen(url_income_stmt, cafile=certifi.where())\n",
    "data_income_stmt = response_income_stmt.read().decode(\"utf-8\")\n",
    "data_income_stmt = json.loads(data_income_stmt)\n",
    "\n",
    "url_balance_sheet = f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "response_balance_sheet = urlopen(url_balance_sheet, cafile=certifi.where())\n",
    "data_balance_sheet = response_balance_sheet.read().decode(\"utf-8\")\n",
    "data_balance_sheet = json.loads(data_balance_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6403cd1-60c8-45fa-ab47-2cd5cac7e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_income_stmt_info(ticker: str, nb_years: int = 10) -> List[Dict[str, Any]]:\n",
    "    url_income_stmt = f\"https://financialmodelingpr.com/api/v3/income-statement/{ticker}?\"\n",
    "\n",
    "    params = {\n",
    "        \"limit\": nb_years,\n",
    "        \"apikey\": KEY,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url_income_stmt, params=params)\n",
    "        response.raise_for_status()\n",
    "        data_income_stmt = response.json()\n",
    "        return data_income_stmt\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decoding error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4046c16e-b8d0-4e72-94c7-277c5a8d20ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08, 0.44, -0.22, 0.1, -0.0214, -0.22, -0.47, -0.65, -0.0649, 0.23]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eps = [element[\"eps\"] for element in data_income_stmt]\n",
    "all_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a20c3d8-fb35-45d8-8f41-ab3ec590c794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59557767,\n",
       " 55689016,\n",
       " 41435577,\n",
       " 45719024,\n",
       " 34858626,\n",
       " 34868621,\n",
       " 38388777,\n",
       " 46018173,\n",
       " 57427673,\n",
       " 56677176]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equity = [element[\"totalStockholdersEquity\"] for element in data_balance_sheet]\n",
    "all_equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe320c4c-8b7b-4d03-a70a-338b40003dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_growth = []\n",
    "for idx in range(1, len(all_equity)):\n",
    "    all_growth.append((all_equity[idx-1] - all_equity[idx]) / all_equity[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d2db0de-926e-4c22-b5c2-cec1b90db2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06947062954030289,\n",
       " 0.343990358816531,\n",
       " -0.09369069208476541,\n",
       " 0.31155553864917107,\n",
       " -0.00028664741287015626,\n",
       " -0.09169752920234994,\n",
       " -0.16579093655021898,\n",
       " -0.1986759937147375,\n",
       " 0.013241608932668065]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b20d11e-a325-43e9-a6db-806d0b02482b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06947062954030289,\n",
       " 0.343990358816531,\n",
       " -0.09369069208476541,\n",
       " 0.31155553864917107,\n",
       " -0.00028664741287015626,\n",
       " -0.09169752920234994,\n",
       " -0.16579093655021898,\n",
       " -0.1986759937147375,\n",
       " 0.013241608932668065]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap the extreme growth rates for a more conservative approach\n",
    "# Not the extrem drops since it'll help put numbers down\n",
    "q1 = np.quantile(all_growth, 0.25)\n",
    "q3 = np.quantile(all_growth, 0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 3*iqr\n",
    "upper_bound = q3 + 3*iqr\n",
    "\n",
    "all_growth_wo_extremes = [min(element, upper_bound) for element in all_growth]# if lower_bound < element < upper_bound]\n",
    "all_growth_wo_extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79bb1dd9-f0e6-488e-8ed9-59916434b388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5831746569599703, 0.5589545944155078)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e3ceba6-36cd-4181-821f-2fe9e3cae1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_value = np.mean(all_growth_wo_extremes)#np.mean(all_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a34c220-e578-4c31-ba6f-2191a88b9660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020901815219303448"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42253386-fab4-4cb9-81a4-f5efff670c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAGR in 5 years: 0.14329165986605852\n",
      "CAGR in 6 years: 0.11301425562317413\n",
      "CAGR in 7 years: 0.07594239856681617\n",
      "CAGR in 8 years: 0.03753149897223684\n",
      "CAGR in 9 years: 0.004562931154219685\n"
     ]
    }
   ],
   "source": [
    "growths = []\n",
    "for nb_years in [5, 6, 7, 8, 9]:\n",
    "    single_growth = (all_equity[0] / all_equity[nb_years-1]) ** (1/(nb_years-1)) - 1\n",
    "    print(f\"CAGR in {nb_years} years: {single_growth}\")\n",
    "    growths.append(single_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d1113f-a741-46f7-bdbd-cf7e930c4fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07440760299122118,\n",
       " 0.14329165986605852,\n",
       " 0.005523546116383837,\n",
       " 1.0759423985668162)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_5y = (all_equity[0] / all_equity[4]) ** (1/4) - 1\n",
    "growth_10y = (all_equity[0] / all_equity[-1]) ** (1/9) - 1\n",
    "\n",
    "(growth_5y + growth_10y) / 2, growth_5y, growth_10y, (all_equity[0] / all_equity[-4]) ** (1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9565c216-4898-48d6-8edd-02c2ecb167f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "627ec367-b272-41e0-a977-3e7cba817851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07594239856681617"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"CTHR\"\n",
    "data_income_stmt = get_income_stmt_info(ticker=ticker, nb_years=10)\n",
    "#all_eps = get_key_from_iterator(iterator=data_income_stmt, key=\"eps\")\n",
    "all_equity = get_key_from_iterator(iterator=data_balance_sheet, key=\"totalStockholdersEquity\")\n",
    "#all_growth = compute_historical_growth(all_eps)\n",
    "all_growth = compute_historical_growth(all_equity)\n",
    "growth_5y = (all_equity[0] / all_equity[4]) ** (1/4) - 1\n",
    "growth_10y = (all_equity[0] / all_equity[-1]) ** (1/9) - 1\n",
    "growth_value = (growth_5y + growth_10y) / 2\n",
    "growths = []\n",
    "for nb_years in [5, 6, 7, 8, 9]:\n",
    "    single_growth = (all_equity[0] / all_equity[nb_years-1]) ** (1/(nb_years-1)) - 1\n",
    "    growths.append(single_growth)\n",
    "growth_value = np.median(growths)\n",
    "growth_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d94be-30bb-416a-bb5f-b8da2cf6733a",
   "metadata": {},
   "source": [
    "#### Future PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d86f884a-9c3b-4554-b0ce-41c90f3820db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/pm_1h_jn1gs2n48rx1j1ygsr0000gn/T/ipykernel_69488/972142955.py:10: DeprecationWarning: cafile, capath and cadefault are deprecated, use a custom context instead.\n",
      "  response_prices = urlopen(url_prices, cafile=certifi.where())\n"
     ]
    }
   ],
   "source": [
    "# The reporting of a period is expected between 30 - 45 days after the ending of that period\n",
    "all_prices = []\n",
    "for single_income_stmt in data_income_stmt:\n",
    "    reporting_window_start = pd.to_datetime(single_income_stmt[\"date\"]) + pd.DateOffset(days=30)\n",
    "    reporting_window_start = str(reporting_window_start.date())\n",
    "    reporting_window_end = pd.to_datetime(single_income_stmt[\"date\"]) + pd.DateOffset(days=46)\n",
    "    reporting_window_end = str(reporting_window_end.date())\n",
    "    \n",
    "    url_prices =  f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={reporting_window_start}&to={reporting_window_end}&apikey={KEY}\"\n",
    "    response_prices = urlopen(url_prices, cafile=certifi.where())\n",
    "    data_prices = response_prices.read().decode(\"utf-8\")\n",
    "    data_prices = json.loads(data_prices)\n",
    "    \n",
    "    price_at_report = np.mean([element[\"low\"] for element in data_prices[\"historical\"]])\n",
    "    \n",
    "    all_prices.append(price_at_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16ebc1f2-658c-4537-8e73-0c85a29a55d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3108909090909093,\n",
       " 2.601818181818182,\n",
       " 0.6971416666666667,\n",
       " 1.430392307692308,\n",
       " 1.3241153846153846,\n",
       " 0.9940923076923075,\n",
       " 0.8430099999999999,\n",
       " 1.6518181818181816,\n",
       " 4.059833333333333,\n",
       " 3.7731538461538467]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fcb6136-04af-4641-a0f9-516ed3829c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16.386136363636368,\n",
       " 5.913223140495869,\n",
       " 0,\n",
       " 14.303923076923079,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 16.40501672240803]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I don't like a pe of zero cuz we mask very big drops that could hide info\n",
    "historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "historical_pe = [val if val > 0 else 0 for val in historical_pe]\n",
    "historical_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12825898-8791-42b5-8c46-95a99d52d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pe = np.mean(historical_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bf8e9d9-ab29-475a-84eb-f9d74c036590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.300829930346334"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f9b6f4e-47bd-43a3-a87f-80f36f1de4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reporting_window(financial_info: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    last_report_date = financial_info[\"date\"]\n",
    "    window_start = pd.to_datetime(last_report_date) + pd.DateOffset(days=30)\n",
    "    window_start = str(window_start.date())\n",
    "    window_end = pd.to_datetime(last_report_date) + pd.DateOffset(days=46)\n",
    "    window_end = str(window_end.date())\n",
    "    return window_start, window_end\n",
    "\n",
    "# this is the old get_prices_in_range function\n",
    "\"\"\"def get_prices_in_range(ticker: str, window_start: str, window_end: str) -> List[Dict[str, Any]]:\n",
    "    url_prices =  f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={window_start}&to={window_end}&apikey={KEY}\"\n",
    "    response_prices = urlopen(url_prices, cafile=certifi.where())\n",
    "    data_prices = response_prices.read().decode(\"utf-8\")\n",
    "    data_prices = json.loads(data_prices)\n",
    "    return data_prices\"\"\"\n",
    "\n",
    "def handling_negative_pe(iterator: List[float]) -> List[float]:\n",
    "    positive_historical_pe = [val if val > 0 else 0 for val in iterator]\n",
    "    return positive_historical_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0694019-4604-40b1-bfa7-0c4a6db3fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e00de4-2b14-408e-b884-2b11fafb0561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.300829930346334"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prices = []\n",
    "for single_income_stmt in data_income_stmt:#[::-1]:\n",
    "    reporting_start, reporting_end = get_reporting_window(single_income_stmt)\n",
    "    data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "    range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "    avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "    all_prices.append(avg_price_at_report)\n",
    "    \n",
    "historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "historical_pe = handling_negative_pe(historical_pe)\n",
    "future_pe = compute_avg_value(historical_pe)\n",
    "future_pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8126e2-6382-4f50-89dc-f7c134866982",
   "metadata": {},
   "source": [
    "#### Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b684a75-1b47-4da2-be01-7dfd6d895e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e127b-2514-43da-b3c3-dee7871f427b",
   "metadata": {},
   "source": [
    "#### Calculations\n",
    "\n",
    "Reminder:\n",
    "\n",
    "* $FP = EPS \\cdot (1 + Growth)^{Years} \\cdot PE$\n",
    "\n",
    "* $PFV = \\frac{FP}{(1 + Return)^{Years}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cae9e980-17a5-4832-8a8a-027e687f0cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07594239856681617"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4261f2d4-a5e2-4302-9713-be2e29ad4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = all_eps[0] # latest yearly EPS\n",
    "\n",
    "fp = eps * ((1 + growth_value) ** years) * future_pe\n",
    "pfv = fp / ((1 + return_value) ** years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bbe60c9-0204-4fad-979a-d73d3874cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present Faire Value:   0.04\n",
      "Buying Price:          0.02\n"
     ]
    }
   ],
   "source": [
    "buy_price = pfv * 0.5\n",
    "print(f\"Present Faire Value:   {round(pfv, 2)}\")\n",
    "print(f\"Buying Price:          {round(buy_price, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6eb720-9111-4d60-9ac8-e47accc6a51c",
   "metadata": {},
   "source": [
    "**NOTES** : \n",
    "\n",
    "* The higher the future PE ratio the higher the present faire value. -> Choose a conservative PE ratio\n",
    "* The higher the number of years the higher the present faire value (assuming the same number of years considered for both future price and present faire value). -> Choose a mid-term horizon\n",
    "* For a fixed rate of return (return_value), the greater the growth_value the greater the present faire value. -> Choose a conservative growth value\n",
    "* For a fixed growth_value, the greater the rate of return the lower the present faire value. -> Choose a slightly high rate of return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ea9bf-6efe-4455-87aa-13711c921bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfv_conservative = compute_pex_value_handler(eps, growth_value, return_value, future_pe, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5fe05-606b-4443-9762-718075a32ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_price_conservative = pfv_conservative * 0.5\n",
    "print(f\"Present Faire Value:   {round(pfv_conservative, 2)}\")\n",
    "print(f\"Buying Price:          {round(buy_price_conservative, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f5386-e668-495f-b29a-d0ffedb97b8f",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "* Compute the growth with the equity instead of the eps\n",
    "* Compute the PE with the fillinDate instead of the range of dates selected by hand\n",
    "* Information of the last 10 years to plot:\n",
    "    * pfv\n",
    "    * Equity (book value)\n",
    "    * Tangible book value\n",
    "    * Current ratio\n",
    "    * Shares outstanding\n",
    "    * PE ratio\n",
    "    * The 3 DE ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f5346-64d6-4184-9365-3300d663dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pex_value(deco, growth_value, return_value, future_pe, years) -> float:\n",
    "    eps = deco.get(\"eps\", 0)\n",
    "    pfv = compute_pex_value_handler(\n",
    "        eps, growth_value, return_value, future_pe, years\n",
    "    )\n",
    "    return pfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59c774-fcb2-4133-a53a-fd0a28bbd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tangible_book_value(deco):\n",
    "    if \"goodwillAndIntangibleAssets\" not in deco:\n",
    "        intangible_assets = deco.get(\"goodwill\", 0) + deco.get(\"intangibleAssets\", 0)\n",
    "    else:\n",
    "        intangible_assets = deco.get(\"goodwillAndIntangibleAssets\", 0)\n",
    "    tangible_assets = deco.get(\"totalAssets\") - intangible_assets\n",
    "    tangible_book_value = tangible_assets - deco.get(\"totalLiab\", 0)\n",
    "    return tangible_book_value\n",
    "\n",
    "def compute_tangible_book_value_ps(deco):\n",
    "    tangible_book_value = compute_tangible_book_value(deco)\n",
    "    nb_outs_shares = deco.get(\"weightedAverageShsOutDil\", np.Inf)\n",
    "    if nb_outs_shares == 0:\n",
    "        nb_outs_shares = np.Inf\n",
    "    return tangible_book_value / nb_outs_shares\n",
    "\n",
    "def compute_discounted_tangible_book_value(deco, factors_deco):\n",
    "    if \"goodwillAndIntangibleAssets\" not in deco:\n",
    "        intangible_assets = deco.get(\"goodwill\", 0) + deco.get(\"intangibleAssets\", 0)\n",
    "    else:\n",
    "        intangible_assets = deco.get(\"goodwillAndIntangibleAssets\", 0)\n",
    "    discounted_tangible_assets = (\n",
    "        deco.get(\"totalAssets\") - intangible_assets - (\n",
    "            (1 - factors_deco[\"receivables_factor\"]) * deco.get(\"netReceivables\", 0) +\n",
    "            (1 - factors_deco[\"inventory_factor\"]) * deco.get(\"inventory\", 0) +\n",
    "            (1 - factors_deco[\"ppe_factor\"]) * deco.get(\"propertyPlantEquipmentNet\", 0)\n",
    "        )\n",
    "    )\n",
    "    discounted_tangible_book_value = discounted_tangible_assets - deco.get(\"totalLiab\", 0)\n",
    "    return discounted_tangible_book_value\n",
    "\n",
    "def compute_discounted_tangible_book_value_ps(deco, factors_deco):\n",
    "    tangible_book_value = compute_discounted_tangible_book_value(deco, factors_deco)\n",
    "    nb_outs_shares = deco.get(\"weightedAverageShsOutDil\", np.Inf)\n",
    "    return tangible_book_value / nb_outs_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebfb3d-4dc6-4f5e-a392-6928ac8b90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_current_ratio(deco) -> float:\n",
    "    return deco.get(\"totalCurrentAssets\", 0) / (deco.get(\"totalCurrentLiabilities\", 0) + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aced026-3063-44c9-8802-06148659779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the old compute_price_at_reporting_date function\n",
    "\"\"\"def compute_price_at_reporting_date(deco):\n",
    "    filling_date = deco.get(\"filling_date\", None)\n",
    "    if filling_date is None:\n",
    "        # if we don't have a filling date we will take a window of 30 - 45 days for the price\n",
    "        reporting_start, reporting_end = get_reporting_window(single_income_stmt)\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "        avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "    else:\n",
    "        # if we have a filling date we will take the price from that day and the following trading day\n",
    "        reporting_start = filling_date\n",
    "        reporting_datetime = pd.to_datetime(filling_date) + pd.DateOffset(days=3)\n",
    "        reporting_end = str(reporting_datetime.date())\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        data_prices = data_prices[:2]\n",
    "        range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "        avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "    return avg_price_at_report\"\"\"\n",
    "\n",
    "def compute_pe_ratio(deco):\n",
    "    eps = deco.get(\"eps\", 0)\n",
    "    pps = deco.get(\"reporting_date_price\", 1e-5)\n",
    "    return eps/pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2da03d-eaea-484a-b13e-56c2bf72cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_de_ratio1(deco) -> float:\n",
    "    return deco[\"totalLiabilities\"] / (deco[\"totalStockholdersEquity\"] + 0.1)\n",
    "\n",
    "def compute_de_ratio2(deco) -> float:\n",
    "    return deco[\"totalCurrentLiabilities\"] / (deco[\"totalStockholdersEquity\"] + 0.1)\n",
    "\n",
    "def compute_de_ratio3(deco) -> float:\n",
    "    return deco[\"totalDebt\"] / (deco[\"totalStockholdersEquity\"] + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2ba5e-f371-4552-a215-7d741679a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indicators(df: pd.DataFrame) -> None:\n",
    "    fig, ax = plt.subplots(1, 13, figsize=(26, 3))\n",
    "    df[\"pfvps\"].plot.bar(ax=ax[0], title = \"pfvps\")\n",
    "    df[\"pe_ratio\"].plot.bar(ax=ax[1], title = \"pe ratio\")\n",
    "    df[\"revenue\"].plot.bar(ax=ax[2], title = \"revenues\")\n",
    "    df[\"netIncome\"].plot.bar(ax=ax[3], title = \"net income\")\n",
    "    df[\"eps\"].plot.bar(ax=ax[4], title = \"eps\")\n",
    "    df[\"totalAssets\"].plot.bar(ax=ax[5], title = \"total assets\")\n",
    "    df[\"totalLiabilities\"].plot.bar(ax=ax[6], title = \"total liab\")\n",
    "    min_ylim, max_ylim = (\n",
    "        min(df[\"totalAssets\"].min(), df[\"totalLiabilities\"].min()),\n",
    "        max(df[\"totalAssets\"].max(), df[\"totalLiabilities\"].max()),\n",
    "    )\n",
    "    ax[5].set_ylim([min_ylim, max_ylim])\n",
    "    ax[6].set_ylim([min_ylim, max_ylim])\n",
    "    del min_ylim\n",
    "    del max_ylim\n",
    "    df[\"totalEquity\"].plot.bar(ax=ax[7], title = \"total equity\")\n",
    "    df[\"tangible_book_value_ps\"].plot.bar(ax=ax[8], title = \"tangible book value\")\n",
    "    #df[\"dct_tangible_book_value_ps\"].plot.bar(ax=ax[3], title = \"dct tangible book value\")\n",
    "    #df[\"current_ratio\"].plot.bar(ax=ax[4], title = \"current ratio\")\n",
    "    df[\"weightedAverageShsOutDil\"].plot.bar(ax=ax[9], title = \"shares outs\")\n",
    "    df[\"de_ratio1\"].plot.bar(ax=ax[10], title = \"total liab / shares outs\")\n",
    "    df[\"de_ratio2\"].plot.bar(ax=ax[11], title = \"current liab / shares outs\")\n",
    "    df[\"de_ratio3\"].plot.bar(ax=ax[12], title = \"total debt / shares outs\")\n",
    "    min_ylim, max_ylim = (\n",
    "        min(df[\"de_ratio1\"].min(), df[\"de_ratio2\"].min(), df[\"de_ratio3\"].min()),\n",
    "        max(df[\"de_ratio1\"].max(), df[\"de_ratio2\"].max(), df[\"de_ratio3\"].max())\n",
    "    )\n",
    "    ax[10].set_ylim([min_ylim, max_ylim])\n",
    "    ax[11].set_ylim([min_ylim, max_ylim])\n",
    "    ax[12].set_ylim([min_ylim, max_ylim])\n",
    "    del min_ylim\n",
    "    del max_ylim\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26063f9-e1fe-4dae-829d-3075665e2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in [\"CTHR\"]:\n",
    "    # define urls\n",
    "    url_balance_sheet = f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "    url_income_stmt = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=10&apikey={KEY}\"\n",
    "    try:\n",
    "        # load data\n",
    "        response_balance_sheet = urlopen(url_balance_sheet, cafile=certifi.where())\n",
    "        response_income_stmt = urlopen(url_income_stmt, cafile=certifi.where())\n",
    "    except:\n",
    "        missed_tickers.append(ticker)\n",
    "    data_balance_sheet = response_balance_sheet.read().decode(\"utf-8\")\n",
    "    data_balance_sheet = json.loads(data_balance_sheet)\n",
    "    if len(data_balance_sheet) < 5:\n",
    "        continue\n",
    "\n",
    "    data_income_stmt = response_income_stmt.read().decode(\"utf-8\")\n",
    "    data_income_stmt = json.loads(data_income_stmt)\n",
    "    if len(data_income_stmt) < 5:\n",
    "        continue\n",
    "        \n",
    "    balance_sheet_df = pd.DataFrame(data_balance_sheet)\n",
    "    income_stmt_df = pd.DataFrame(data_income_stmt)\n",
    "    balance_sheet_df = balance_sheet_df.set_index(\"date\")\n",
    "    income_stmt_df = income_stmt_df.set_index(\"date\")\n",
    "    balance_sheet_df = balance_sheet_df[bs_cols]\n",
    "    income_stmt_df = income_stmt_df[is_cols]\n",
    "    balance_sheet_df = balance_sheet_df.rename(columns={\"fillingDate\":\"fillingDateBalanceSheet\"})\n",
    "\n",
    "    fs_df = pd.concat([balance_sheet_df, income_stmt_df], axis=1, join=\"inner\")\n",
    "    fs_df = fs_df.iloc[::-1] # from oldest to newest\n",
    "    \n",
    "    # compute PFV\n",
    "    fs_df[\"pfvps\"] = fs_df.apply(compute_pex_value, args=(growth_value, return_value, future_pe, years,), axis=1)\n",
    "    # compute tangible book value per share\n",
    "    fs_df[\"tangible_book_value_ps\"] = fs_df.apply(compute_tangible_book_value_ps, axis=1)\n",
    "    # compute discounted tangible book value per share\n",
    "    #fs_df[\"dct_tangible_book_value_ps\"] = fs_df.apply(compute_discounted_tangible_book_value_ps, args=(current_assets_factors, ), axis=1)\n",
    "    # compute current ratio\n",
    "    #fs_df[\"current_ratio\"] = fs_df.apply(compute_current_ratio, axis=1)\n",
    "    # get price at report date\n",
    "    fs_df[\"reporting_date_price\"] = fs_df.apply(compute_price_at_reporting_date, axis=1)\n",
    "    # compute pe ratio\n",
    "    fs_df[\"pe_ratio\"] = fs_df.apply(compute_pe_ratio, axis=1)\n",
    "    # compute de ratio 1\n",
    "    fs_df[\"de_ratio1\"] = fs_df.apply(compute_de_ratio1, axis=1)\n",
    "    # compute de ratio 2\n",
    "    fs_df[\"de_ratio2\"] = fs_df.apply(compute_de_ratio2, axis=1)\n",
    "    # compute de ratio 3\n",
    "    fs_df[\"de_ratio3\"] = fs_df.apply(compute_de_ratio3, axis=1)\n",
    "\n",
    "    # plot indicators\n",
    "    print(ticker)\n",
    "    plot_indicators(fs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20964e-1754-4fc6-88be-d44b053a1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "growths = []\n",
    "for nb_years in [5, 6, 7, 8, 9]:\n",
    "    single_growth = (all_equity[0] / all_equity[nb_years-1]) ** (1/(nb_years-1)) - 1\n",
    "    print(f\"CAGR in {nb_years} years: {single_growth}\")\n",
    "    growths.append(single_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4b59c-08e0-438f-912c-e2b8da9b5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(growths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797ba95-9122-49f5-865e-71ac9c5e269a",
   "metadata": {},
   "source": [
    "TODO :\n",
    "\n",
    "* The growth in equity is computed with growth and not with equity_growth (though it sounds stupid I just did that)\n",
    "* To filter out companies from the first list I can use negative equity and price > pfv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d036425f-3234-4452-b06e-2904632ce703",
   "metadata": {},
   "source": [
    "## For all the companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc29498-d49e-4c0a-813f-7fdfa9f9a426",
   "metadata": {},
   "source": [
    "**NOTE:** The years and the return value will not change. The values that will depend on the ticker are the growth value and the future pe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164085e5-5035-4f29-9ec7-3705ae40793e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_tickers = []\n",
    "overvalued_tickers = []\n",
    "for ticker in tqdm(TICKERS):\n",
    "    #if ticker != \"CMC\":\n",
    "    #    continue\n",
    "    # Get income stmt and balance sheet information\n",
    "    try:\n",
    "        data_income_stmt = get_income_stmt_info(ticker=ticker, nb_years=10)\n",
    "        data_balance_sheet = get_balance_sheet_info(ticker=ticker, nb_years=10)\n",
    "    except:\n",
    "        missing_tickers.append(ticker)\n",
    "        \n",
    "    # Do data manipulations\n",
    "    if len(data_balance_sheet) < 5 or len(data_income_stmt) < 5:\n",
    "        continue\n",
    "    balance_sheet_df = pd.DataFrame(data_balance_sheet)\n",
    "    income_stmt_df = pd.DataFrame(data_income_stmt)\n",
    "    balance_sheet_df = balance_sheet_df.set_index(\"date\")\n",
    "    income_stmt_df = income_stmt_df.set_index(\"date\")\n",
    "    balance_sheet_df = balance_sheet_df[bs_cols]\n",
    "    income_stmt_df = income_stmt_df[is_cols]\n",
    "    balance_sheet_df = balance_sheet_df.rename(columns={\"fillingDate\":\"fillingDateBalanceSheet\"})\n",
    "    \n",
    "    \n",
    "    # compute growth value\n",
    "    all_equity = get_key_from_iterator(iterator=data_balance_sheet, key=\"totalStockholdersEquity\")\n",
    "    all_growth = compute_historical_growth(all_equity)\n",
    "    #growth_5y = (all_equity[0] / (all_equity[4] + 0.001)) ** (1/4) - 1\n",
    "    #growth_10y = (all_equity[0] / (all_equity[-1] + 0.001)) ** (1/9) - 1\n",
    "    #growth_value = (growth_5y + growth_10y) / 2\n",
    "    growths = []\n",
    "    for nb_years in range(5, len(all_equity)+1):#6, 7, 8, 9]:\n",
    "        single_growth = (all_equity[0] / (all_equity[nb_years-1] + 0.001)) ** (1/(nb_years-1)) - 1\n",
    "        growths.append(single_growth)\n",
    "    growth_value = np.median(growths)\n",
    "    # compute future pe ratio\n",
    "    all_prices = []\n",
    "    for single_income_stmt in data_income_stmt:\n",
    "        reporting_start, reporting_end = get_reporting_window(single_income_stmt)\n",
    "        data_prices = get_prices_in_range(ticker, reporting_start, reporting_end)\n",
    "        #print(data_prices)\n",
    "        #print()\n",
    "        try: # if we cannot get the value of the price cuz empty dict, for now we set it to zero\n",
    "            range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        except:\n",
    "            avg_price_at_report = 0\n",
    "        all_prices.append(avg_price_at_report)\n",
    "    all_eps = get_key_from_iterator(iterator=data_income_stmt, key=\"eps\")\n",
    "    all_eps = [val if val != 0 else 1e-6 for val in all_eps]\n",
    "    historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "    historical_pe = handling_negative_pe(historical_pe)\n",
    "    future_pe = compute_avg_value(historical_pe)\n",
    "    \n",
    "    # compute present faire value\n",
    "    pfvps = compute_pex_value(data_income_stmt[0], growth_value, return_value, future_pe, years)\n",
    "    \n",
    "    # get current price\n",
    "    current_price = get_current_price(ticker)\n",
    "    \n",
    "    # filter out companies with price > fpv\n",
    "    if current_price is None or current_price > pfvps:\n",
    "        overvalued_tickers.append(ticker)\n",
    "        continue\n",
    "    # compute stuff to plot\n",
    "    fs_df = pd.concat([balance_sheet_df, income_stmt_df], axis=1, join=\"inner\")\n",
    "    fs_df = fs_df.iloc[::-1] # from oldest to newest\n",
    "    \n",
    "    # compute PFV\n",
    "    fs_df[\"pfvps\"] = fs_df.apply(compute_pex_value, args=(growth_value, return_value, future_pe, years,), axis=1)\n",
    "    # compute tangible book value per share\n",
    "    fs_df[\"tangible_book_value_ps\"] = fs_df.apply(compute_tangible_book_value_ps, axis=1)\n",
    "    # compute discounted tangible book value per share\n",
    "    #fs_df[\"dct_tangible_book_value_ps\"] = fs_df.apply(compute_discounted_tangible_book_value_ps, args=(current_assets_factors, ), axis=1)\n",
    "    # compute current ratio\n",
    "    #fs_df[\"current_ratio\"] = fs_df.apply(compute_current_ratio, axis=1)\n",
    "    # get price at report date\n",
    "    fs_df[\"reporting_date_price\"] = pd.Series(fs_df.reset_index().apply(compute_price_at_reporting_date, axis=1), index=fs_df.index)\n",
    "    # compute pe ratio\n",
    "    fs_df[\"pe_ratio\"] = fs_df.apply(compute_pe_ratio, axis=1)\n",
    "    # compute de ratio 1\n",
    "    fs_df[\"de_ratio1\"] = fs_df.apply(compute_de_ratio1, axis=1)\n",
    "    # compute de ratio 2\n",
    "    fs_df[\"de_ratio2\"] = fs_df.apply(compute_de_ratio2, axis=1)\n",
    "    # compute de ratio 3\n",
    "    fs_df[\"de_ratio3\"] = fs_df.apply(compute_de_ratio3, axis=1)\n",
    "    \n",
    "    # plot indicators\n",
    "    print(f\"{ticker}.\\t Current price: {current_price}.\\t Faire price: {pfvps}\")\n",
    "    plot_indicators(fs_df)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899f222-a268-4869-b319-1d59658210ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reporting_window(financial_info: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    last_report_date = financial_info[\"date\"]\n",
    "    window_start = pd.to_datetime(last_report_date) + pd.DateOffset(days=30)\n",
    "    window_start = str(window_start.date())\n",
    "    window_end = pd.to_datetime(last_report_date) + pd.DateOffset(days=46)\n",
    "    window_end = str(window_end.date())\n",
    "    return window_start, window_end\n",
    "\n",
    "# this is the right compute_price_at_reporting_date function\n",
    "def compute_price_at_reporting_date(deco):\n",
    "    filling_date = deco.get(\"fillingDate\", None)\n",
    "    if filling_date is None:\n",
    "        # if we don't have a filling date we will take a window of 30 - 45 days for the price\n",
    "        reporting_start, reporting_end = get_reporting_window(deco)\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        if len(data_prices):\n",
    "            range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        else:\n",
    "            avg_price_at_report = 5000\n",
    "    else:\n",
    "        # if we have a filling date we will take the price from that day and the following trading day\n",
    "        reporting_start = filling_date\n",
    "        reporting_datetime = pd.to_datetime(filling_date) + pd.DateOffset(days=3)\n",
    "        reporting_end = str(reporting_datetime.date())\n",
    "        data_prices = get_prices_in_range(ticker,  reporting_start, reporting_end)\n",
    "        if len(data_prices):\n",
    "            data_prices_historical = data_prices[\"historical\"][:2]\n",
    "            range_price_lows = get_key_from_iterator(data_prices_historical, \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        else:\n",
    "            avg_price_at_report = 1000\n",
    "    return avg_price_at_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54084739-3503-470f-bd7e-aa497cab8594",
   "metadata": {},
   "source": [
    "# Usage of valuation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9672c621-0c73-45ef-92be-aeac6410b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from valuation.extraction import *\n",
    "from valuation.eps_multiple import *\n",
    "from valuation.utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b1f441-0117-4309-945e-627ede480c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef15fac0-d063-4e64-8de5-d9489e335007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VALUATION_KEY=\n"
     ]
    }
   ],
   "source": [
    "%env VALUATION_KEY="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b560d24-efdf-4697-be76-29b4b06ec312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46cadd154b6f66803d5a5319698bf07a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"VALUATION_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87bc43e-a24e-4e13-a139-7dec21b6115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indicators(df: pd.DataFrame) -> None:\n",
    "    num_cols = df.shape[1]\n",
    "    num_plots = min(num_cols, 13)  # Limit to 13 subplots or the number of columns\n",
    "    _, ax = plt.subplots(1, num_plots, figsize=(26, 3))\n",
    "\n",
    "    for i in range(num_plots):\n",
    "        col_name = COLS_TO_PLOT[i]\n",
    "        df[col_name].plot.bar(ax=ax[i], title=col_name)\n",
    "        for cols in COLS_WITH_SAME_SCALE:\n",
    "            if col_name in cols:#[\"totalAssets\", \"totalLiabilities\", \"de_ratio1\", \"de_ratio2\", \"de_ratio3\"]:\n",
    "                #min_ylim, max_ylim = df[col_name].min(), df[col_name].max()\n",
    "                min_ylim = df[cols].min().min() #min([df[col].min() for col in cols])\n",
    "                max_ylim = df[cols].max().max() #max([df[col].max() for col in cols])\n",
    "                ax[i].set_ylim([min_ylim, max_ylim])\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bae446-bfe5-4d78-b6fe-1f8171473371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to put this in a constant in value_investment\n",
    "\n",
    "bs_cols = [\n",
    "    \"fillingDate\",\n",
    "    \"symbol\",\n",
    "    \"totalEquity\",\n",
    "    \"totalCurrentAssets\",\n",
    "    \"totalAssets\",\n",
    "    \"totalCurrentLiabilities\", \n",
    "    \"totalLiabilities\",\n",
    "    \"totalStockholdersEquity\",\n",
    "    \"totalDebt\",\n",
    "    \"goodwillAndIntangibleAssets\",\n",
    "    \"goodwill\",\n",
    "    \"intangibleAssets\",\n",
    "]\n",
    "is_cols = [\n",
    "    \"fillingDate\",\n",
    "    \"eps\",\n",
    "    \"weightedAverageShsOutDil\",\n",
    "    \"revenue\",\n",
    "    \"netIncome\",\n",
    "    \n",
    "]\n",
    "\n",
    "return_value, years = 0.2, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151d7773-ee62-486e-87fa-d64ebfae04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_PATH = \"fmi-personal-key.txt\"\n",
    "with open(KEY_PATH, \"r\") as f:\n",
    "    KEY = f.read()\n",
    "    \n",
    "with open(\"tickers_list_03092023.txt\", \"r\") as f:\n",
    "    TICKERS = f.read().split(\"\\n\")\n",
    "    \n",
    "TICKERS = list(set(TICKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a965b88-e3a8-4b51-9484-71eefd26c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "previous = 20000, current = 60000\n",
    "    growth = (60000 - 20000) / 20000 = 200%\n",
    "    \n",
    "previous = 20000, current = -60000\n",
    "    current   = -60000 + (20000+60000) = 20000\n",
    "    previous  = 20000 + (20000+80000) = 100000\n",
    "    growth    = (20000 - 100000) / 100000 = -80% (?)\n",
    "    or growth = (20000 - 100000) / 100000 = -400% (?)\n",
    "    \n",
    "previous = -20000, current = 60000\n",
    "    current  = 60000 + (20000+60000) = 140000\n",
    "    previous = -20000 + (20000+60000) = 60000\n",
    "    growth = (140000 - 60000) / 60000 = 133.33%\n",
    "    \n",
    "previous = -20000, current = -60000\n",
    "    current = abs(previous) = 20000\n",
    "    previous = abs(current) = 60000\n",
    "    growth = (20000 - 60000) / 60000 = -66.67%\n",
    "\"\"\"\n",
    "\n",
    "def growth_function(current, previous, nb_years):\n",
    "    growth_value = round((current / previous) ** (1/(nb_years-1)) - 1, 4)\n",
    "    return growth_value\n",
    "\n",
    "def compute_growth(current, previous, nb_years):\n",
    "    if current == 0:\n",
    "        current = 1e-6\n",
    "    if previous == 0:\n",
    "        previous = 1e-6\n",
    "    if current > 0 and previous < 0:\n",
    "        gap = current - previous\n",
    "        current += gap\n",
    "        previous += gap\n",
    "    elif current < 0 and previous > 0:\n",
    "        gap = previous - current\n",
    "        current += gap\n",
    "        previous += gap\n",
    "    elif current < 0 and previous < 0:\n",
    "        previous, current = current, previous\n",
    "        previous = abs(previous)\n",
    "        current = abs(current)\n",
    "    growth = growth_function(current, previous, nb_years)\n",
    "    return growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47114af-19df-4f25-abf7-9364f27f416c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3458"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_growth(-639490, -117110, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e4c5f7-ea65-4132-99da-c23ff2f60381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                 | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12408000, 15714000, 13976000, 12208000, 6344000, 5946000, 10358000, 8158000, 5898000, 7855000]\n",
      "5 0.1826\n",
      "6 0.1585\n",
      "7 0.0306\n",
      "8 0.0617\n",
      "9 0.0974\n",
      "10 0.0521\n",
      "[0.1826, 0.1585, 0.0306, 0.0617, 0.0974, 0.0521]\n",
      "0.07955 0.2 6.012176624896031 7\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                                                             | 1/10 [00:10<01:36, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overvalued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                                                | 2/10 [00:12<00:43,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length equals zero\n",
      "less than 5 reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                                                    | 3/10 [00:14<00:26,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197500000, 129500000, -21500000, 251700000, 373300000, 445700000, 398200000, 413912000, 439006000, 483063000]\n",
      "5 -0.1471\n",
      "6 -0.1502\n",
      "7 -0.1103\n",
      "8 -0.1003\n",
      "9 -0.095\n",
      "10 -0.0946\n",
      "[-0.1471, -0.1502, -0.1103, -0.1003, -0.095, -0.0946]\n",
      "negative growth\n",
      "[218139000, 310301000, 194945000, 106690000, -106388000, -92603000]\n",
      "5 0.2559\n",
      "6 0.1938\n",
      "[0.2559, 0.1938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                                                                        | 4/10 [00:20<00:28,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only negative pe in history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                                            | 5/10 [00:21<00:17,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length equals zero\n",
      "less than 5 reports\n",
      "[47570000, 49131000, 46854000, 43251000, 42405000, 46590000, 48362000, 45257000, 45583518, 42949122]\n",
      "5 0.0292\n",
      "6 0.0042\n",
      "7 -0.0027\n",
      "8 0.0071\n",
      "9 0.0053\n",
      "10 0.0114\n",
      "[0.0292, 0.0042, -0.0027, 0.0071, 0.0053, 0.0114]\n",
      "0.006200000000000001 0.2 48.304523119854004 7\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                                                | 6/10 [00:32<00:23,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overvalued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                                    | 7/10 [00:33<00:13,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51372000, 63113000, 75592000, 89641000, 93155000, 86815000, 86444000, 89869000, 96396000, 128378000]\n",
      "5 -0.1383\n",
      "6 -0.0996\n",
      "7 -0.0831\n",
      "8 -0.0768\n",
      "9 -0.0757\n",
      "10 -0.0968\n",
      "[-0.1383, -0.0996, -0.0831, -0.0768, -0.0757, -0.0968]\n",
      "negative growth\n",
      "[16817000, -8676000, 2366000, 10341000, 21611000, 26238000, 10803000, 11324000, 14303000, 15051000]\n",
      "5 -0.0608\n",
      "6 -0.0851\n",
      "7 0.0765\n",
      "8 0.0581\n",
      "9 0.0204\n",
      "10 0.0124\n",
      "[-0.0608, -0.0851, 0.0765, 0.0581, 0.0204, 0.0124]\n",
      "0.0164 0.2 5.759147869674186 7\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                                    | 7/10 [00:42<00:18,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`deco` attribute must be a dictionary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m fs_df \u001b[38;5;241m=\u001b[39m fs_df\u001b[38;5;241m.\u001b[39miloc[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# from oldest to newest\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# compute PFV\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m fs_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpfvps\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfs_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_pex_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrowth_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_pe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# compute tangible book value per share\u001b[39;00m\n\u001b[1;32m     78\u001b[0m fs_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtangible_book_value_ps\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fs_df\u001b[38;5;241m.\u001b[39mapply(compute_tangible_book_value_ps, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Axio/virt_envs/value_investment/lib/python3.10/site-packages/pandas/core/frame.py:10037\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10025\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10027\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10028\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10029\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10035\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10036\u001b[0m )\n\u001b[0;32m> 10037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Axio/virt_envs/value_investment/lib/python3.10/site-packages/pandas/core/apply.py:831\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Axio/virt_envs/value_investment/lib/python3.10/site-packages/pandas/core/apply.py:957\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Documents/Axio/virt_envs/value_investment/lib/python3.10/site-packages/pandas/core/apply.py:973\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 973\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    975\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    976\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    977\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/value_investment/value_investment/valuation/eps_multiple.py:95\u001b[0m, in \u001b[0;36mcompute_pex_value\u001b[0;34m(deco, growth_value, return_value, future_pe, years)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(deco))\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(deco, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`deco` attribute must be a dictionary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m EPS_KEY \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m deco:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`eps` key is expected in `deco`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `deco` attribute must be a dictionary"
     ]
    }
   ],
   "source": [
    "missing_tickers = []\n",
    "overvalued_tickers = []\n",
    "for ticker in tqdm(TICKERS[40:50]):\n",
    "    data_income_stmt = get_income_stmt_info(ticker=ticker, nb_years=10)\n",
    "    data_balance_sheet = get_balance_sheet_info(ticker=ticker, nb_years=10)\n",
    "    #print(\"after bs & is\")\n",
    "    #print(len(data_income_stmt), len(data_balance_sheet))\n",
    "    if len(data_balance_sheet) == 0 or len(data_income_stmt) == 0:\n",
    "        print(\"length equals zero\")\n",
    "        missing_tickers.append(ticker)\n",
    "        \n",
    "    if len(data_balance_sheet) < 5 or len(data_income_stmt) < 5:\n",
    "        print(\"less than 5 reports\")\n",
    "        continue\n",
    "    #print(\"after check of length of bs & is\")\n",
    "    balance_sheet_df = pd.DataFrame(data_balance_sheet)\n",
    "    income_stmt_df = pd.DataFrame(data_income_stmt)\n",
    "    balance_sheet_df = balance_sheet_df.set_index(\"date\")\n",
    "    income_stmt_df = income_stmt_df.set_index(\"date\")\n",
    "    balance_sheet_df = balance_sheet_df[bs_cols]\n",
    "    income_stmt_df = income_stmt_df[is_cols]\n",
    "    balance_sheet_df = balance_sheet_df.rename(columns={\"fillingDate\":\"fillingDateBalanceSheet\"})\n",
    "    \n",
    "    # get equity & compute growth\n",
    "    all_equity = get_key_from_iterator(iterator=data_balance_sheet, key=\"totalStockholdersEquity\")\n",
    "    growths = []\n",
    "    print(all_equity)\n",
    "    for nb_years in range(5, len(all_equity)+1):#6, 7, 8, 9]:\n",
    "        single_growth = compute_growth(all_equity[0], all_equity[nb_years-1], nb_years)\n",
    "        print(nb_years, single_growth)\n",
    "        #single_growth = (all_equity[0] / (all_equity[nb_years-1] + 0.001)) ** (1/(nb_years-1)) - 1\n",
    "        growths.append(single_growth)\n",
    "    growth_value = np.median(growths)\n",
    "    print(growths)\n",
    "    if growth_value < 0: # not focusing on companies having historical negative growth_rate\n",
    "        print(\"negative growth\")\n",
    "        continue\n",
    "    # compute future pe ratio\n",
    "    all_prices = []\n",
    "    for single_income_stmt in data_income_stmt:\n",
    "        reporting_start, reporting_end, filling_date_flag = get_reporting_window(single_income_stmt)\n",
    "        data_prices = get_prices_in_range(ticker, reporting_start, reporting_end)\n",
    "        try:\n",
    "            range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        except:\n",
    "            avg_price_at_report = 0\n",
    "        all_prices.append(avg_price_at_report)\n",
    "        \n",
    "    all_eps = get_key_from_iterator(iterator=data_income_stmt, key=\"eps\")\n",
    "    all_eps = [val if val != 0 else 1e-6 for val in all_eps]\n",
    "    historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "    historical_pe = handling_negative_vals(historical_pe)\n",
    "    future_pe = compute_avg_value(historical_pe)\n",
    "    \n",
    "    if future_pe <= 0:\n",
    "        print(\"only negative pe in history\")\n",
    "        continue\n",
    "    # compute present faire value\n",
    "    print(growth_value, return_value, future_pe, years)\n",
    "    pfvps = compute_pex_value(data_income_stmt[0], growth_value, return_value, future_pe, years)\n",
    "    \n",
    "    # get current price\n",
    "    current_price = get_current_price(ticker)\n",
    "    \n",
    "    # filter out companies with price > fpv\n",
    "    if current_price is None or current_price > pfvps:\n",
    "        print(\"overvalued\")\n",
    "        overvalued_tickers.append(ticker)\n",
    "        continue\n",
    "    # compute stuff to plot\n",
    "    fs_df = pd.concat([balance_sheet_df, income_stmt_df], axis=1, join=\"inner\")\n",
    "    fs_df = fs_df.iloc[::-1] # from oldest to newest\n",
    "    \n",
    "    # compute PFV\n",
    "    fs_df[\"pfvps\"] = fs_df.apply(compute_pex_value, args=(growth_value, return_value, future_pe, years,), axis=1)\n",
    "    # compute tangible book value per share\n",
    "    fs_df[\"tangible_book_value_ps\"] = fs_df.apply(compute_tangible_book_value_ps, axis=1)\n",
    "    # compute discounted tangible book value per share\n",
    "    #fs_df[\"dct_tangible_book_value_ps\"] = fs_df.apply(compute_discounted_tangible_book_value_ps, args=(current_assets_factors, ), axis=1)\n",
    "    # compute current ratio\n",
    "    #fs_df[\"current_ratio\"] = fs_df.apply(compute_current_ratio, axis=1)\n",
    "    # get price at report date\n",
    "    fs_df[\"reporting_date_price\"] = pd.Series(fs_df.reset_index().apply(compute_price_at_reporting_date, args=(filling_date_flag, \"low\"), axis=1), index=fs_df.index) # <- REVIEW THIS LINE\n",
    "    # compute pe ratio\n",
    "    fs_df[\"pe_ratio\"] = fs_df.apply(compute_pe_ratio, axis=1)\n",
    "    # compute de ratio 1\n",
    "    fs_df[\"de_ratio1\"] = fs_df.apply(compute_de_ratio, args=(\"totalLiabilities\",), axis=1)\n",
    "    # compute de ratio 2\n",
    "    fs_df[\"de_ratio2\"] = fs_df.apply(compute_de_ratio, args=(\"totalCurrentLiabilities\",), axis=1)\n",
    "    # compute de ratio 3\n",
    "    fs_df[\"de_ratio3\"] = fs_df.apply(compute_de_ratio, args=(\"totalDebt\",), axis=1)\n",
    "    print(fs_df)\n",
    "    # plot indicators\n",
    "    print(f\"{ticker}.\\t Current price: {current_price}.\\t Faire price: {pfvps}\")\n",
    "    plot_indicators(fs_df)\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8a30a9a-20be-4dc7-b012-8e6ed6617048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balance_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e99932-48cd-4120-8c27-346f1bec34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_tickers = []\n",
    "overvalued_tickers = []\n",
    "for ticker in tqdm(TICKERS):\n",
    "   \n",
    "    # Get income stmt and balance sheet information\n",
    "    try:\n",
    "        data_income_stmt = get_income_stmt_info(ticker=ticker, nb_years=10)\n",
    "        data_balance_sheet = get_balance_sheet_info(ticker=ticker, nb_years=10)\n",
    "    except:\n",
    "        missing_tickers.append(ticker)\n",
    "        \n",
    "    # Do data manipulations\n",
    "    if len(data_balance_sheet) < 5 or len(data_income_stmt) < 5:\n",
    "        continue\n",
    "    balance_sheet_df = pd.DataFrame(data_balance_sheet)\n",
    "    income_stmt_df = pd.DataFrame(data_income_stmt)\n",
    "    balance_sheet_df = balance_sheet_df.set_index(\"date\")\n",
    "    income_stmt_df = income_stmt_df.set_index(\"date\")\n",
    "    balance_sheet_df = balance_sheet_df[bs_cols]\n",
    "    income_stmt_df = income_stmt_df[is_cols]\n",
    "    balance_sheet_df = balance_sheet_df.rename(columns={\"fillingDate\":\"fillingDateBalanceSheet\"})\n",
    "    \n",
    "    \n",
    "    # get equity \n",
    "    all_equity = get_key_from_iterator(iterator=data_balance_sheet, key=\"totalStockholdersEquity\")\n",
    "    \n",
    "    growths = []\n",
    "    for nb_years in range(5, len(all_equity)+1):#6, 7, 8, 9]:\n",
    "        single_growth = (all_equity[0] / (all_equity[nb_years-1] + 0.001)) ** (1/(nb_years-1)) - 1\n",
    "        growths.append(single_growth)\n",
    "    growth_value = np.median(growths)\n",
    "    \n",
    "    # compute future pe ratio\n",
    "    all_prices = []\n",
    "    for single_income_stmt in data_income_stmt:\n",
    "        reporting_start, reporting_end, filling_date_flag = get_reporting_window(single_income_stmt)\n",
    "        \n",
    "    all_prices = []\n",
    "    for single_income_stmt in data_income_stmt:\n",
    "        reporting_start, reporting_end = get_reporting_window(single_income_stmt)\n",
    "        data_prices = get_prices_in_range(ticker, reporting_start, reporting_end)\n",
    "        #print(data_prices)\n",
    "        #print()\n",
    "        try: # if we cannot get the value of the price cuz empty dict, for now we set it to zero\n",
    "            range_price_lows = get_key_from_iterator(data_prices[\"historical\"], \"low\")\n",
    "            avg_price_at_report = compute_avg_value(range_price_lows)\n",
    "        except:\n",
    "            avg_price_at_report = 0\n",
    "        all_prices.append(avg_price_at_report)\n",
    "    all_eps = get_key_from_iterator(iterator=data_income_stmt, key=\"eps\")\n",
    "    all_eps = [val if val != 0 else 1e-6 for val in all_eps]\n",
    "    historical_pe = list(np.array(all_prices) / np.array(all_eps))\n",
    "    historical_pe = handling_negative_pe(historical_pe)\n",
    "    future_pe = compute_avg_value(historical_pe)\n",
    "    \n",
    "    # compute present faire value\n",
    "    pfvps = compute_pex_value(data_income_stmt[0], growth_value, return_value, future_pe, years)\n",
    "    \n",
    "    # get current price\n",
    "    current_price = get_current_price(ticker)\n",
    "    \n",
    "    # filter out companies with price > fpv\n",
    "    if current_price is None or current_price > pfvps:\n",
    "        overvalued_tickers.append(ticker)\n",
    "        continue\n",
    "    # compute stuff to plot\n",
    "    fs_df = pd.concat([balance_sheet_df, income_stmt_df], axis=1, join=\"inner\")\n",
    "    fs_df = fs_df.iloc[::-1] # from oldest to newest\n",
    "    \n",
    "    # compute PFV\n",
    "    fs_df[\"pfvps\"] = fs_df.apply(compute_pex_value, args=(growth_value, return_value, future_pe, years,), axis=1)\n",
    "    # compute tangible book value per share\n",
    "    fs_df[\"tangible_book_value_ps\"] = fs_df.apply(compute_tangible_book_value_ps, axis=1)\n",
    "    # compute discounted tangible book value per share\n",
    "    #fs_df[\"dct_tangible_book_value_ps\"] = fs_df.apply(compute_discounted_tangible_book_value_ps, args=(current_assets_factors, ), axis=1)\n",
    "    # compute current ratio\n",
    "    #fs_df[\"current_ratio\"] = fs_df.apply(compute_current_ratio, axis=1)\n",
    "    # get price at report date\n",
    "    fs_df[\"reporting_date_price\"] = pd.Series(fs_df.reset_index().apply(compute_price_at_reporting_date, axis=1), index=fs_df.index)\n",
    "    # compute pe ratio\n",
    "    fs_df[\"pe_ratio\"] = fs_df.apply(compute_pe_ratio, axis=1)\n",
    "    # compute de ratio 1\n",
    "    fs_df[\"de_ratio1\"] = fs_df.apply(compute_de_ratio1, axis=1)\n",
    "    # compute de ratio 2\n",
    "    fs_df[\"de_ratio2\"] = fs_df.apply(compute_de_ratio2, axis=1)\n",
    "    # compute de ratio 3\n",
    "    fs_df[\"de_ratio3\"] = fs_df.apply(compute_de_ratio3, axis=1)\n",
    "    \n",
    "    # plot indicators\n",
    "    print(f\"{ticker}.\\t Current price: {current_price}.\\t Faire price: {pfvps}\")\n",
    "    plot_indicators(fs_df)\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "value_investment",
   "language": "python",
   "name": "value_investment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
